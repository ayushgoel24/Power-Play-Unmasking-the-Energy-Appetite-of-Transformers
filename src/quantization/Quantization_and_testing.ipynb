{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quantization_and_testing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d0640e52a0ae4341a8c059e2f4c15660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_caedef66ca444227a9ca21019b98cfe3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e4b621c01e5b4f728ca70d21b75b195c",
              "IPY_MODEL_19411f185e2847bcb5926246b76cacf6"
            ]
          }
        },
        "caedef66ca444227a9ca21019b98cfe3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4b621c01e5b4f728ca70d21b75b195c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_256446086414462393f3a675d34fb4f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_854fd5ffd9b54ec39c1e0df513958f87"
          }
        },
        "19411f185e2847bcb5926246b76cacf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0611180d7554d2881e645db5d260b1c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:18&lt;00:00, 9138963.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d247b7d77b0481eb4c5e523b09fb92d"
          }
        },
        "256446086414462393f3a675d34fb4f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "854fd5ffd9b54ec39c1e0df513958f87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0611180d7554d2881e645db5d260b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d247b7d77b0481eb4c5e523b09fb92d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjeqD_6AGW31"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "import copy"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2lzHUtOGaZ4"
      },
      "source": [
        "class QuantizeNetwork(object):\n",
        "  def __init__(self, verbose = True):\n",
        "    self.model = None\n",
        "    self.num_cluster = None\n",
        "    self.verbose = verbose\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  def quantize_network(self,model,num_cluster):\n",
        "    self.model = copy.deepcopy(model)\n",
        "    self.num_cluster = num_cluster\n",
        "    self._k_means_quantization(self.model.features._modules.items())\n",
        "    self._k_means_quantization(self.model.classifier._modules.items())\n",
        "    self.model = torch.quantization.quantize_dynamic( self.model, {torch.nn.BatchNorm2d,torch.nn.Conv2d},  dtype=torch.qint8) \n",
        "    return self.model\n",
        "\n",
        "  def _k_means_quantization(self,modules):\n",
        "    for layer, (name, module) in enumerate(modules):\n",
        "      if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "        weight = module.weight.data.cpu().numpy()\n",
        "        org_shape =  module.weight.shape\n",
        "        flatten_weights = weight.flatten()\n",
        "        old_unique_weights = np.unique(flatten_weights)\n",
        "        space = np.linspace(np.min(flatten_weights), np.max(flatten_weights), num=2**self.num_cluster)\n",
        "        kclusters = KMeans(n_clusters=len(space), init=space.reshape(-1,1), n_init=1, precompute_distances=True, algorithm=\"full\")\n",
        "        kclusters.fit(weight.reshape(-1,1))\n",
        "        new_weight = kclusters.cluster_centers_[kclusters.labels_].reshape(-1)\n",
        "        new_unique_weights = np.unique(new_weight)\n",
        "        module.weight.data = torch.from_numpy(new_weight.reshape(org_shape)).to(self.device)\n",
        "        if self.verbose:\n",
        "          print('layer_names [',module,'] -> unique weights count old:',len(old_unique_weights),', new:',len(new_unique_weights))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp-_k-FcMRsb"
      },
      "source": [
        "# Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VDP8rWiMS1e",
        "outputId": "5e701d9c-375d-46a3-ca5e-5737ed61385e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "checkpoint_loc = '/content/gdrive/MyDrive/11785/project/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixmE0MeMMryz"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision import transforms"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGFcKeuyMdIU"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "INIT_LR = 0.1\n",
        "WEIGHT_DECAY_RATE = 0.0005\n",
        "EPOCHS = 70\n",
        "lr_decay_interval = 10\n",
        "batch_size = 128"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahQ0lpN2MeUE"
      },
      "source": [
        "VGG_CONFIGS = {\n",
        "    # M for MaxPool, Number for channels\n",
        "    'D': [\n",
        "        64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M',\n",
        "        512, 512, 512, 'M'\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_SNIP(nn.Module):\n",
        "    \"\"\"\n",
        "    This is a base class to generate three VGG variants used in SNIP paper:\n",
        "        1. VGG-C (16 layers)\n",
        "        2. VGG-D (16 layers)\n",
        "        3. VGG-like\n",
        "\n",
        "    Some of the differences:\n",
        "        * Reduced size of FC layers to 512\n",
        "        * Adjusted flattening to match CIFAR-10 shapes\n",
        "        * Replaced dropout layers with BatchNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = self.make_layers(VGG_CONFIGS[config], batch_norm=True)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512),  # 512 * 7 * 7 in the original VGG\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm1d(512),  # instead of dropout\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm1d(512),  # instead of dropout\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def make_layers(config, batch_norm=False):  # TODO: BN yes or no?\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in config:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [\n",
        "                        conv2d,\n",
        "                        nn.BatchNorm2d(v),\n",
        "                        nn.ReLU(inplace=True)\n",
        "                    ]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)  \n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5152X9jGMhkE"
      },
      "source": [
        "def get_cifar10_dataloaders(train_batch_size, test_batch_size):\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10('_dataset', True, train_transform, download=True)\n",
        "    test_dataset = CIFAR10('_dataset', False, test_transform, download=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        test_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrPRCqgzMj4z"
      },
      "source": [
        "def cifar10_experiment():\n",
        "    \n",
        "    BATCH_SIZE = 128\n",
        "    LR_DECAY_INTERVAL = 20\n",
        "    \n",
        "    net = VGG_SNIP('D').to(device)\n",
        "    # net = \n",
        "    optimiser = optim.SGD(\n",
        "        net.parameters(),\n",
        "        lr=INIT_LR,\n",
        "        momentum=0.9,\n",
        "        weight_decay=WEIGHT_DECAY_RATE)\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(\n",
        "        optimiser, LR_DECAY_INTERVAL, gamma=0.1)\n",
        "    \n",
        "    train_loader, val_loader = get_cifar10_dataloaders(BATCH_SIZE,\n",
        "                                                       BATCH_SIZE)  # TODO\n",
        "\n",
        "    return net, optimiser, lr_scheduler, train_loader, val_loader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d0640e52a0ae4341a8c059e2f4c15660",
            "caedef66ca444227a9ca21019b98cfe3",
            "e4b621c01e5b4f728ca70d21b75b195c",
            "19411f185e2847bcb5926246b76cacf6",
            "256446086414462393f3a675d34fb4f1",
            "854fd5ffd9b54ec39c1e0df513958f87",
            "e0611180d7554d2881e645db5d260b1c",
            "2d247b7d77b0481eb4c5e523b09fb92d"
          ]
        },
        "id": "LAogCE_DMjx6",
        "outputId": "af756697-875b-40b7-f855-119161ad765b"
      },
      "source": [
        "initial_net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "initial_net = initial_net.to(device)\n",
        "torch.save(initial_net,'/content/init.pt')\n",
        "initial_net"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to _dataset/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0640e52a0ae4341a8c059e2f4c15660",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting _dataset/cifar-10-python.tar.gz to _dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG_SNIP(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnoQ0_L_MwRk"
      },
      "source": [
        "# load after pruned network and perform quantization.\n",
        "after_pruning_net = torch.load('/content/gdrive/MyDrive/11785/project/check/after_pruning.ptmodel')\n",
        "after_pruning_net = after_pruning_net.cuda()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUGPEDkuNeOG"
      },
      "source": [
        "import time\n",
        "\n",
        "def validate(epoch, model, criterion, device, data_loader):\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        running_loss, accuracy,total  = 0.0, 0.0, 0\n",
        "\n",
        "        \n",
        "        for i, (X, Y) in enumerate(data_loader):\n",
        "            \n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            output= model(X)\n",
        "            loss = criterion(output, Y.long())\n",
        "\n",
        "            _,pred_labels = torch.max(F.softmax(output, dim=1), 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            \n",
        "            accuracy += torch.sum(torch.eq(pred_labels, Y)).item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total += len(X)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            del X\n",
        "            del Y\n",
        "        \n",
        "        return running_loss/total, accuracy/total, (time.time() - start_time)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwXEGfu-NaxY",
        "outputId": "3b1f4fc1-d823-489c-aeca-21a0291575f9"
      },
      "source": [
        " criterion = nn.CrossEntropyLoss()\n",
        " val_loss, val_acc,time_taken = validate(0, after_pruning_net, criterion, device, val_loader)\n",
        " print(val_loss, ' ', val_acc,' ',time_taken)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0022592162996530533   0.9193   2.32389760017395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyHwXLG4Nkt8"
      },
      "source": [
        "Testing using quantization new code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3tbnDegNiw8",
        "outputId": "6ed20f08-77a0-4772-a721-5e3451ac01ec"
      },
      "source": [
        "q_net = QuantizeNetwork()\n",
        "q_network = q_net.quantize_network(after_pruning_net,5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer_names [ Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 1590 , new: 32\n",
            "layer_names [ BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 64 , new: 32\n",
            "layer_names [ Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 26883 , new: 32\n",
            "layer_names [ BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 64 , new: 32\n",
            "layer_names [ Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 47853 , new: 32\n",
            "layer_names [ BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 128 , new: 32\n",
            "layer_names [ Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 76178 , new: 32\n",
            "layer_names [ BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 128 , new: 32\n",
            "layer_names [ Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 111327 , new: 32\n",
            "layer_names [ BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 256 , new: 32\n",
            "layer_names [ Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 133452 , new: 32\n",
            "layer_names [ BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 256 , new: 32\n",
            "layer_names [ Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 108554 , new: 32\n",
            "layer_names [ BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 256 , new: 32\n",
            "layer_names [ Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 97934 , new: 32\n",
            "layer_names [ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 512 , new: 32\n",
            "layer_names [ Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 55523 , new: 32\n",
            "layer_names [ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 512 , new: 32\n",
            "layer_names [ Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 32482 , new: 32\n",
            "layer_names [ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 512 , new: 32\n",
            "layer_names [ Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 29773 , new: 32\n",
            "layer_names [ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 507 , new: 32\n",
            "layer_names [ Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 18410 , new: 32\n",
            "layer_names [ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 507 , new: 32\n",
            "layer_names [ Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ] -> unique weights count old: 11140 , new: 32\n",
            "layer_names [ BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 497 , new: 32\n",
            "layer_names [ Linear(in_features=512, out_features=512, bias=True) ] -> unique weights count old: 8298 , new: 32\n",
            "layer_names [ BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 235 , new: 32\n",
            "layer_names [ Linear(in_features=512, out_features=512, bias=True) ] -> unique weights count old: 874 , new: 32\n",
            "layer_names [ BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ] -> unique weights count old: 236 , new: 32\n",
            "layer_names [ Linear(in_features=512, out_features=10, bias=True) ] -> unique weights count old: 1318 , new: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_BwCEGcPFxM",
        "outputId": "efe3d496-2285-4cf8-c83d-b2d1fca90916"
      },
      "source": [
        " criterion = nn.CrossEntropyLoss()\n",
        " val_loss, val_acc,time_taken = validate(0, q_network, criterion, device, val_loader)\n",
        " print(val_loss, ' ', val_acc,' ',time_taken)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0022042215384542943   0.9184   2.4405198097229004\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}