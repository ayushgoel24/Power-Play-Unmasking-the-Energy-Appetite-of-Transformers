{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deep Depression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84daf540d6b34b9e89b6302746cf1650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3ecc680a42dd43bc980202afee31910d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65cb0f3303b04691998df41b0cd5e0e9",
              "IPY_MODEL_c79079522f274a73acc6c9915f2cbcc9"
            ]
          }
        },
        "3ecc680a42dd43bc980202afee31910d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65cb0f3303b04691998df41b0cd5e0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c04e0a8dd52a4f3a8b9073a7466a1d7d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6dd6e4832f214a399611bdb8add0c75b"
          }
        },
        "c79079522f274a73acc6c9915f2cbcc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a567b7e3beb642748da43d055b0f106d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [03:41&lt;00:00, 771368.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_730f031134c4468eae0aa0b293d443f9"
          }
        },
        "c04e0a8dd52a4f3a8b9073a7466a1d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6dd6e4832f214a399611bdb8add0c75b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a567b7e3beb642748da43d055b0f106d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "730f031134c4468eae0aa0b293d443f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlVSCmvnf7YH"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqQKwO50f1kU",
        "outputId": "f752b5b8-97d0-42a0-bd34-2a3b03f04bb3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "checkpoint_loc = '/content/gdrive/MyDrive/11785/project/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG2hQJH6gIzB"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "\n",
        "import copy\n",
        "import types"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoA2K8xugTBX"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "INIT_LR = 0.1\n",
        "WEIGHT_DECAY_RATE = 0.0005\n",
        "EPOCHS = 70\n",
        "REPEAT_WITH_DIFFERENT_SEED = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGsK22PdgUbJ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h93qZmKlgYRE"
      },
      "source": [
        "VGG_CONFIGS = {\n",
        "    # M for MaxPool, Number for channels\n",
        "    'D': [\n",
        "        64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M',\n",
        "        512, 512, 512, 'M'\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_SNIP(nn.Module):\n",
        "    \"\"\"\n",
        "    This is a base class to generate three VGG variants used in SNIP paper:\n",
        "        1. VGG-C (16 layers)\n",
        "        2. VGG-D (16 layers)\n",
        "        3. VGG-like\n",
        "\n",
        "    Some of the differences:\n",
        "        * Reduced size of FC layers to 512\n",
        "        * Adjusted flattening to match CIFAR-10 shapes\n",
        "        * Replaced dropout layers with BatchNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = self.make_layers(VGG_CONFIGS[config], batch_norm=True)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512),  # 512 * 7 * 7 in the original VGG\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm1d(512),  # instead of dropout\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm1d(512),  # instead of dropout\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def make_layers(config, batch_norm=False):  # TODO: BN yes or no?\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in config:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [\n",
        "                        conv2d,\n",
        "                        nn.BatchNorm2d(v),\n",
        "                        nn.ReLU(inplace=True)\n",
        "                    ]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)  \n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDLqrb37gaqm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78H6ZQVrgb9C"
      },
      "source": [
        "# Dataset and loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P0SQQeNgg30"
      },
      "source": [
        "def get_cifar10_dataloaders(train_batch_size, test_batch_size):\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10('_dataset', True, train_transform, download=True)\n",
        "    test_dataset = CIFAR10('_dataset', False, test_transform, download=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        test_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boYCdWBOgjJa"
      },
      "source": [
        "def cifar10_experiment():\n",
        "    \n",
        "    BATCH_SIZE = 128\n",
        "    LR_DECAY_INTERVAL = 20\n",
        "    \n",
        "    net = VGG_SNIP('D').to(device)\n",
        "    # net = \n",
        "    optimiser = optim.SGD(\n",
        "        net.parameters(),\n",
        "        lr=INIT_LR,\n",
        "        momentum=0.9,\n",
        "        weight_decay=WEIGHT_DECAY_RATE)\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(\n",
        "        optimiser, LR_DECAY_INTERVAL, gamma=0.1)\n",
        "    \n",
        "    train_loader, val_loader = get_cifar10_dataloaders(BATCH_SIZE,\n",
        "                                                       BATCH_SIZE)  # TODO\n",
        "\n",
        "    return net, optimiser, lr_scheduler, train_loader, val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "84daf540d6b34b9e89b6302746cf1650",
            "3ecc680a42dd43bc980202afee31910d",
            "65cb0f3303b04691998df41b0cd5e0e9",
            "c79079522f274a73acc6c9915f2cbcc9",
            "c04e0a8dd52a4f3a8b9073a7466a1d7d",
            "6dd6e4832f214a399611bdb8add0c75b",
            "a567b7e3beb642748da43d055b0f106d",
            "730f031134c4468eae0aa0b293d443f9"
          ]
        },
        "id": "tRYSlTNrgkJs",
        "outputId": "c90ab07b-e562-4e25-bbc6-d36b281d5813"
      },
      "source": [
        "net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "net = net.to(device)\n",
        "torch.save(net,'/content/init.pt')\n",
        "net"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to _dataset/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84daf540d6b34b9e89b6302746cf1650",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting _dataset/cifar-10-python.tar.gz to _dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG_SNIP(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUifGE_bhwRO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jNCk-s9i6G8"
      },
      "source": [
        "# Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFIi-BL8vZMk"
      },
      "source": [
        "SNIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c8pwhf7sbdy"
      },
      "source": [
        "def snip_forward_conv2d(self, x):\n",
        "        return F.conv2d(x, self.weight * self.weight_mask, self.bias,\n",
        "                        self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "\n",
        "def snip_forward_linear(self, x):\n",
        "        return F.linear(x, self.weight * self.weight_mask, self.bias)\n",
        "\n",
        "\n",
        "def SNIP(net, keep_ratio, train_dataloader, device):\n",
        "    # TODO: shuffle?\n",
        "\n",
        "    # Grab a single batch from the training dataset\n",
        "    inputs, targets = next(iter(train_dataloader))\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Let's create a fresh copy of the network so that we're not worried about\n",
        "    # affecting the actual training-phase\n",
        "    net = copy.deepcopy(net)\n",
        "\n",
        "    # Monkey-patch the Linear and Conv2d layer to learn the multiplicative mask\n",
        "    # instead of the weights\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight))\n",
        "            nn.init.xavier_normal_(layer.weight)\n",
        "            layer.weight.requires_grad = False\n",
        "\n",
        "        # Override the forward methods:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
        "\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            layer.forward = types.MethodType(snip_forward_linear, layer)\n",
        "\n",
        "    # Compute gradients (but don't apply them)\n",
        "    net.zero_grad()\n",
        "    outputs = net.forward(inputs)\n",
        "    loss = F.nll_loss(outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    grads_abs = []\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            grads_abs.append(torch.abs(layer.weight_mask.grad))\n",
        "\n",
        "    # Gather all scores in a single vector and normalise\n",
        "    all_scores = torch.cat([torch.flatten(x) for x in grads_abs])\n",
        "    norm_factor = torch.sum(all_scores)\n",
        "    all_scores.div_(norm_factor)\n",
        "\n",
        "    num_params_to_keep = int(len(all_scores) * keep_ratio)\n",
        "    threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\n",
        "    acceptable_score = threshold[-1]\n",
        "\n",
        "    keep_masks = []\n",
        "    for g in grads_abs:\n",
        "        keep_masks.append(((g / norm_factor) >= acceptable_score).float())\n",
        "        \n",
        "    print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\n",
        "\n",
        "    return (keep_masks)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLxN9Y0Ov2eD"
      },
      "source": [
        "def apply_prune_mask(net, keep_masks):\n",
        "\n",
        "    # Before I can zip() layers and pruning masks I need to make sure they match\n",
        "    # one-to-one by removing all the irrelevant modules:\n",
        "    prunable_layers = filter(\n",
        "        lambda layer: isinstance(layer, nn.Conv2d) or isinstance(\n",
        "            layer, nn.Linear), net.modules())\n",
        "\n",
        "    for layer, keep_mask in zip(prunable_layers, keep_masks):\n",
        "        assert (layer.weight.shape == keep_mask.shape)\n",
        "\n",
        "        def hook_factory(keep_mask):\n",
        "            \"\"\"\n",
        "            The hook function can't be defined directly here because of Python's\n",
        "            late binding which would result in all hooks getting the very last\n",
        "            mask! Getting it through another function forces early binding.\n",
        "            \"\"\"\n",
        "\n",
        "            def hook(grads):\n",
        "                return grads * keep_mask\n",
        "\n",
        "            return hook\n",
        "\n",
        "        # mask[i] == 0 --> Prune parameter\n",
        "        # mask[i] == 1 --> Keep parameter\n",
        "\n",
        "        # Step 1: Set the masked weights to zero (NB the biases are ignored)\n",
        "        # Step 2: Make sure their gradients remain zero\n",
        "        layer.weight.data[keep_mask == 0.] = 0.\n",
        "        layer.weight.register_hook(hook_factory(keep_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF-FcEgVjbnY"
      },
      "source": [
        "# Pruning while training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbTQd0fYj38y"
      },
      "source": [
        "def training(epoch, model, optimizer, scheduler, criterion, device, train_loader):\n",
        "  model.train()\n",
        "  avg_loss = 0.0\n",
        "  av_loss=0.0\n",
        "  total=0\n",
        "  for batch_num, (feats, labels) in enumerate(train_loader):\n",
        "      feats, labels = feats.to(device), labels.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(feats)\n",
        "\n",
        "\n",
        "      loss = criterion(outputs, labels.long())\n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "      \n",
        "      avg_loss += loss.item()\n",
        "      av_loss += loss.item() \n",
        "      total +=len(feats) \n",
        "      # if batch_num % 10 == 9:\n",
        "      #     print('Epoch: {}\\tBatch: {}\\tAv-Loss: {:.4f}'.format(epoch+1, batch_num+1, av_loss/10))\n",
        "      #     av_loss = 0.0\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      del feats\n",
        "      del labels\n",
        "      del loss\n",
        "\n",
        "  del train_loader\n",
        "  return avg_loss/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhOefkNFwG3S"
      },
      "source": [
        "def validate(epoch, model, criterion, device, data_loader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        running_loss, accuracy,total  = 0.0, 0.0, 0\n",
        "\n",
        "        \n",
        "        for i, (X, Y) in enumerate(data_loader):\n",
        "            \n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            output= model(X)\n",
        "            loss = criterion(output, Y.long())\n",
        "\n",
        "            _,pred_labels = torch.max(F.softmax(output, dim=1), 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            \n",
        "            accuracy += torch.sum(torch.eq(pred_labels, Y)).item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total += len(X)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            del X\n",
        "            del Y\n",
        "        \n",
        "        return running_loss/total, accuracy/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwlFxHpSwJrC"
      },
      "source": [
        "def train():\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "\n",
        "    # Pre-training pruning using SKIP\n",
        "    keep_masks = SNIP(net, 0.05, train_loader, device)  # TODO: shuffle?\n",
        "    apply_prune_mask(net, keep_masks)\n",
        "    #training(net, optimiser, scheduler,F.nll_loss, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJrAtHiArxhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38e21dfd-7177-4c0d-a102-86f0520022f0"
      },
      "source": [
        "for _ in range(REPEAT_WITH_DIFFERENT_SEED):\n",
        "      #train()\n",
        "      net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "      net = net.to(device)\n",
        "      # Pre-training pruning using SKIP\n",
        "      keep_masks = SNIP(net, 0.05, train_loader, device)  # TODO: shuffle?\n",
        "      apply_prune_mask(net, keep_masks)\n",
        "      \n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "      for epoch in range(EPOCHS):\n",
        "          train_loss = training(epoch, net, optimiser, lr_scheduler, criterion, device,train_loader)\n",
        "\n",
        "          val_loss, val_acc = validate(epoch, net, criterion, device, val_loader)\n",
        "\n",
        "          lr_scheduler.step()\n",
        "\n",
        "          print('Epoch: {} \\t train-Loss: {:.4f}, \\tval-Loss: {:.4f}, \\tval-acc: {:.4f}'.format(epoch+1,  train_loss, val_loss, val_acc))\n",
        "\n",
        "      torch.save(net,checkpoint_loc+'depression_1.ptmodel')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "tensor(761993, device='cuda:0')\n",
            "Epoch: 1 \t train-Loss: 0.0128, \tval-Loss: 0.0109, \tval-acc: 0.5027\n",
            "Epoch: 2 \t train-Loss: 0.0084, \tval-Loss: 0.0089, \tval-acc: 0.6318\n",
            "Epoch: 3 \t train-Loss: 0.0064, \tval-Loss: 0.0065, \tval-acc: 0.7141\n",
            "Epoch: 4 \t train-Loss: 0.0054, \tval-Loss: 0.0067, \tval-acc: 0.7155\n",
            "Epoch: 5 \t train-Loss: 0.0049, \tval-Loss: 0.0062, \tval-acc: 0.7318\n",
            "Epoch: 6 \t train-Loss: 0.0046, \tval-Loss: 0.0050, \tval-acc: 0.7791\n",
            "Epoch: 7 \t train-Loss: 0.0044, \tval-Loss: 0.0059, \tval-acc: 0.7495\n",
            "Epoch: 8 \t train-Loss: 0.0042, \tval-Loss: 0.0056, \tval-acc: 0.7554\n",
            "Epoch: 9 \t train-Loss: 0.0041, \tval-Loss: 0.0055, \tval-acc: 0.7586\n",
            "Epoch: 10 \t train-Loss: 0.0040, \tval-Loss: 0.0054, \tval-acc: 0.7708\n",
            "Epoch: 11 \t train-Loss: 0.0039, \tval-Loss: 0.0079, \tval-acc: 0.6881\n",
            "Epoch: 12 \t train-Loss: 0.0038, \tval-Loss: 0.0048, \tval-acc: 0.7988\n",
            "Epoch: 13 \t train-Loss: 0.0038, \tval-Loss: 0.0051, \tval-acc: 0.7750\n",
            "Epoch: 14 \t train-Loss: 0.0038, \tval-Loss: 0.0058, \tval-acc: 0.7549\n",
            "Epoch: 15 \t train-Loss: 0.0036, \tval-Loss: 0.0050, \tval-acc: 0.7931\n",
            "Epoch: 16 \t train-Loss: 0.0036, \tval-Loss: 0.0059, \tval-acc: 0.7455\n",
            "Epoch: 17 \t train-Loss: 0.0035, \tval-Loss: 0.0051, \tval-acc: 0.7805\n",
            "Epoch: 18 \t train-Loss: 0.0035, \tval-Loss: 0.0056, \tval-acc: 0.7673\n",
            "Epoch: 19 \t train-Loss: 0.0035, \tval-Loss: 0.0038, \tval-acc: 0.8359\n",
            "Epoch: 20 \t train-Loss: 0.0035, \tval-Loss: 0.0046, \tval-acc: 0.8021\n",
            "Epoch: 21 \t train-Loss: 0.0023, \tval-Loss: 0.0024, \tval-acc: 0.8960\n",
            "Epoch: 22 \t train-Loss: 0.0019, \tval-Loss: 0.0023, \tval-acc: 0.9002\n",
            "Epoch: 23 \t train-Loss: 0.0017, \tval-Loss: 0.0023, \tval-acc: 0.9033\n",
            "Epoch: 24 \t train-Loss: 0.0016, \tval-Loss: 0.0022, \tval-acc: 0.9052\n",
            "Epoch: 25 \t train-Loss: 0.0015, \tval-Loss: 0.0022, \tval-acc: 0.9048\n",
            "Epoch: 26 \t train-Loss: 0.0014, \tval-Loss: 0.0022, \tval-acc: 0.9042\n",
            "Epoch: 27 \t train-Loss: 0.0013, \tval-Loss: 0.0022, \tval-acc: 0.9091\n",
            "Epoch: 28 \t train-Loss: 0.0012, \tval-Loss: 0.0023, \tval-acc: 0.9054\n",
            "Epoch: 29 \t train-Loss: 0.0012, \tval-Loss: 0.0022, \tval-acc: 0.9081\n",
            "Epoch: 30 \t train-Loss: 0.0011, \tval-Loss: 0.0023, \tval-acc: 0.9033\n",
            "Epoch: 31 \t train-Loss: 0.0011, \tval-Loss: 0.0024, \tval-acc: 0.9041\n",
            "Epoch: 32 \t train-Loss: 0.0011, \tval-Loss: 0.0024, \tval-acc: 0.9049\n",
            "Epoch: 33 \t train-Loss: 0.0010, \tval-Loss: 0.0023, \tval-acc: 0.9076\n",
            "Epoch: 34 \t train-Loss: 0.0010, \tval-Loss: 0.0024, \tval-acc: 0.9035\n",
            "Epoch: 35 \t train-Loss: 0.0010, \tval-Loss: 0.0024, \tval-acc: 0.9014\n",
            "Epoch: 36 \t train-Loss: 0.0010, \tval-Loss: 0.0024, \tval-acc: 0.9051\n",
            "Epoch: 37 \t train-Loss: 0.0010, \tval-Loss: 0.0024, \tval-acc: 0.9035\n",
            "Epoch: 38 \t train-Loss: 0.0009, \tval-Loss: 0.0026, \tval-acc: 0.8986\n",
            "Epoch: 39 \t train-Loss: 0.0009, \tval-Loss: 0.0027, \tval-acc: 0.8970\n",
            "Epoch: 40 \t train-Loss: 0.0009, \tval-Loss: 0.0026, \tval-acc: 0.9004\n",
            "Epoch: 41 \t train-Loss: 0.0007, \tval-Loss: 0.0022, \tval-acc: 0.9142\n",
            "Epoch: 42 \t train-Loss: 0.0006, \tval-Loss: 0.0021, \tval-acc: 0.9167\n",
            "Epoch: 43 \t train-Loss: 0.0005, \tval-Loss: 0.0021, \tval-acc: 0.9159\n",
            "Epoch: 44 \t train-Loss: 0.0005, \tval-Loss: 0.0021, \tval-acc: 0.9174\n",
            "Epoch: 45 \t train-Loss: 0.0005, \tval-Loss: 0.0021, \tval-acc: 0.9182\n",
            "Epoch: 46 \t train-Loss: 0.0004, \tval-Loss: 0.0021, \tval-acc: 0.9165\n",
            "Epoch: 47 \t train-Loss: 0.0004, \tval-Loss: 0.0021, \tval-acc: 0.9185\n",
            "Epoch: 48 \t train-Loss: 0.0004, \tval-Loss: 0.0021, \tval-acc: 0.9177\n",
            "Epoch: 49 \t train-Loss: 0.0004, \tval-Loss: 0.0022, \tval-acc: 0.9182\n",
            "Epoch: 50 \t train-Loss: 0.0004, \tval-Loss: 0.0022, \tval-acc: 0.9184\n",
            "Epoch: 51 \t train-Loss: 0.0004, \tval-Loss: 0.0022, \tval-acc: 0.9197\n",
            "Epoch: 52 \t train-Loss: 0.0003, \tval-Loss: 0.0022, \tval-acc: 0.9171\n",
            "Epoch: 53 \t train-Loss: 0.0003, \tval-Loss: 0.0022, \tval-acc: 0.9181\n",
            "Epoch: 54 \t train-Loss: 0.0003, \tval-Loss: 0.0022, \tval-acc: 0.9196\n",
            "Epoch: 55 \t train-Loss: 0.0003, \tval-Loss: 0.0022, \tval-acc: 0.9185\n",
            "Epoch: 56 \t train-Loss: 0.0003, \tval-Loss: 0.0022, \tval-acc: 0.9194\n",
            "Epoch: 57 \t train-Loss: 0.0003, \tval-Loss: 0.0022, \tval-acc: 0.9185\n",
            "Epoch: 58 \t train-Loss: 0.0003, \tval-Loss: 0.0022, \tval-acc: 0.9168\n",
            "Epoch: 59 \t train-Loss: 0.0003, \tval-Loss: 0.0023, \tval-acc: 0.9173\n",
            "Epoch: 60 \t train-Loss: 0.0003, \tval-Loss: 0.0023, \tval-acc: 0.9193\n",
            "Epoch: 61 \t train-Loss: 0.0003, \tval-Loss: 0.0023, \tval-acc: 0.9195\n",
            "Epoch: 62 \t train-Loss: 0.0003, \tval-Loss: 0.0023, \tval-acc: 0.9197\n",
            "Epoch: 63 \t train-Loss: 0.0002, \tval-Loss: 0.0023, \tval-acc: 0.9183\n",
            "Epoch: 64 \t train-Loss: 0.0002, \tval-Loss: 0.0022, \tval-acc: 0.9192\n",
            "Epoch: 65 \t train-Loss: 0.0002, \tval-Loss: 0.0023, \tval-acc: 0.9179\n",
            "Epoch: 66 \t train-Loss: 0.0003, \tval-Loss: 0.0023, \tval-acc: 0.9181\n",
            "Epoch: 67 \t train-Loss: 0.0002, \tval-Loss: 0.0022, \tval-acc: 0.9191\n",
            "Epoch: 68 \t train-Loss: 0.0002, \tval-Loss: 0.0023, \tval-acc: 0.9197\n",
            "Epoch: 69 \t train-Loss: 0.0003, \tval-Loss: 0.0023, \tval-acc: 0.9186\n",
            "Epoch: 70 \t train-Loss: 0.0002, \tval-Loss: 0.0023, \tval-acc: 0.9193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB9l6iFR7FzR"
      },
      "source": [
        "# torch.save(net,'after_pruning.ptmodel')\n",
        "net = torch.load('/content/gdrive/MyDrive/11785/project/deep depression/after_pruning.ptmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S3bwXnTpJ6v",
        "outputId": "1aa0e6f4-6491-4950-de22-138bbb228130"
      },
      "source": [
        " criterion = nn.CrossEntropyLoss()\n",
        " val_loss, val_acc = validate(0, net, criterion, device, val_loader)\n",
        " print(val_loss, ' ', val_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0022592162996530533   0.9193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOb17YiRr0Dy"
      },
      "source": [
        "# Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAwR8XXd6Ik-"
      },
      "source": [
        "Sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK3rMqHB9x3f",
        "outputId": "f9f1bd52-b196-4e98-e501-228fd4dbd264"
      },
      "source": [
        "net.features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (5): ReLU(inplace=True)\n",
              "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (9): ReLU(inplace=True)\n",
              "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (12): ReLU(inplace=True)\n",
              "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (16): ReLU(inplace=True)\n",
              "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (19): ReLU(inplace=True)\n",
              "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (22): ReLU(inplace=True)\n",
              "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (26): ReLU(inplace=True)\n",
              "  (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (29): ReLU(inplace=True)\n",
              "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (32): ReLU(inplace=True)\n",
              "  (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (36): ReLU(inplace=True)\n",
              "  (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (39): ReLU(inplace=True)\n",
              "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (42): ReLU(inplace=True)\n",
              "  (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lIE0Qk66crJ",
        "outputId": "a013963d-5332-419d-dc47-eab23d181a48"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "bits = 5\n",
        "for layer, (name, module) in enumerate(net.features._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    dev = module.weight.device\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    org_shape =  module.weight.shape\n",
        "\n",
        "    flatten_weights = weight.flatten()\n",
        "    min_ = np.min(flatten_weights)\n",
        "    max_ = np.max(flatten_weights)\n",
        "    space = np.linspace(min_, max_, num=2**bits)\n",
        "\n",
        "    print(module.weight.flatten().size())\n",
        "    kmeans = KMeans(n_clusters=len(space), init=space.reshape(-1,1), n_init=1, precompute_distances=True, algorithm=\"full\")\n",
        "    kmeans.fit(weight.reshape(-1,1))\n",
        "    new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(-1)\n",
        "    mat = new_weight.reshape(org_shape)\n",
        "    module.weight.data = torch.from_numpy(mat).to(dev)\n",
        "\n",
        "  else:\n",
        "    print('skipped')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------  name: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1728])\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([64])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([36864])\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([64])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([73728])\n",
            "----------  name: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([128])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([147456])\n",
            "----------  name: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([128])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([294912])\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([256])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([589824])\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([256])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([589824])\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([256])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1179648])\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([2359296])\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([2359296])\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([2359296])\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([2359296])\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([2359296])\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ8Qx_gQUN_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "947d18ea-9be1-4814-e3f3-939495ae224a"
      },
      "source": [
        " val_loss, val_acc = validate(0, net, criterion, device, val_loader)\n",
        " print(val_acc)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf6CsKV-a_5r"
      },
      "source": [
        "torch.save(net,'after_quantization.ptmodel')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFh5pRGbbNDL"
      },
      "source": [
        "while(True):"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}