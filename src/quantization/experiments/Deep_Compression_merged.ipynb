{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Deep Depression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80a314a1a2604204afdcf1e172bdd419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c47ef7664b934df789e005c471b4770f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4a7027bce3f487cace0abac8bed4416",
              "IPY_MODEL_d43a24386fca4fde9bd5deb2718e3e14"
            ]
          }
        },
        "c47ef7664b934df789e005c471b4770f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4a7027bce3f487cace0abac8bed4416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2646449a643246ae82cd5667bc48d4b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_264d93517c0f48e29d56294c4f9adb59"
          }
        },
        "d43a24386fca4fde9bd5deb2718e3e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2ec56c45abbc422b88043689553ca538",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:18&lt;00:00, 9414610.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcc2fe0eedd44f76877e95da369f3fae"
          }
        },
        "2646449a643246ae82cd5667bc48d4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "264d93517c0f48e29d56294c4f9adb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ec56c45abbc422b88043689553ca538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcc2fe0eedd44f76877e95da369f3fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlVSCmvnf7YH"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqQKwO50f1kU",
        "outputId": "a3379797-ff83-4834-9559-6f231affba93"
      },
      "source": [
        "from google.colab import drive.\n",
        "drive.mount('/content/gdrive')\n",
        "checkpoint_loc = '/content/gdrive/MyDrive/11785/project/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG2hQJH6gIzB"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "\n",
        "import copy\n",
        "import types"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoA2K8xugTBX"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "INIT_LR = 0.1\n",
        "WEIGHT_DECAY_RATE = 0.0005\n",
        "EPOCHS = 70\n",
        "REPEAT_WITH_DIFFERENT_SEED = 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGsK22PdgUbJ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h93qZmKlgYRE"
      },
      "source": [
        "VGG_CONFIGS = {\n",
        "    # M for MaxPool, Number for channels\n",
        "    'D': [\n",
        "        64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M',\n",
        "        512, 512, 512, 'M'\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_SNIP(nn.Module):\n",
        "    \"\"\"\n",
        "    This is a base class to generate three VGG variants used in SNIP paper:\n",
        "        1. VGG-C (16 layers)\n",
        "        2. VGG-D (16 layers)\n",
        "        3. VGG-like\n",
        "\n",
        "    Some of the differences:\n",
        "        * Reduced size of FC layers to 512\n",
        "        * Adjusted flattening to match CIFAR-10 shapes\n",
        "        * Replaced dropout layers with BatchNorm\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = self.make_layers(VGG_CONFIGS[config], batch_norm=True)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 512),  # 512 * 7 * 7 in the original VGG\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm1d(512),  # instead of dropout\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(True),\n",
        "            nn.BatchNorm1d(512),  # instead of dropout\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def make_layers(config, batch_norm=False):  # TODO: BN yes or no?\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in config:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [\n",
        "                        conv2d,\n",
        "                        nn.BatchNorm2d(v),\n",
        "                        nn.ReLU(inplace=True)\n",
        "                    ]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)  \n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78H6ZQVrgb9C"
      },
      "source": [
        "# Dataset and loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P0SQQeNgg30"
      },
      "source": [
        "def get_cifar10_dataloaders(train_batch_size, test_batch_size):\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10('_dataset', True, train_transform, download=True)\n",
        "    test_dataset = CIFAR10('_dataset', False, test_transform, download=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        test_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boYCdWBOgjJa"
      },
      "source": [
        "def cifar10_experiment():\n",
        "    \n",
        "    BATCH_SIZE = 128\n",
        "    LR_DECAY_INTERVAL = 20\n",
        "    \n",
        "    net = VGG_SNIP('D').to(device)\n",
        "    # net = \n",
        "    optimiser = optim.SGD(\n",
        "        net.parameters(),\n",
        "        lr=INIT_LR,\n",
        "        momentum=0.9,\n",
        "        weight_decay=WEIGHT_DECAY_RATE)\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(\n",
        "        optimiser, LR_DECAY_INTERVAL, gamma=0.1)\n",
        "    \n",
        "    train_loader, val_loader = get_cifar10_dataloaders(BATCH_SIZE,\n",
        "                                                       BATCH_SIZE)  # TODO\n",
        "\n",
        "    return net, optimiser, lr_scheduler, train_loader, val_loader"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "80a314a1a2604204afdcf1e172bdd419",
            "c47ef7664b934df789e005c471b4770f",
            "a4a7027bce3f487cace0abac8bed4416",
            "d43a24386fca4fde9bd5deb2718e3e14",
            "2646449a643246ae82cd5667bc48d4b2",
            "264d93517c0f48e29d56294c4f9adb59",
            "2ec56c45abbc422b88043689553ca538",
            "fcc2fe0eedd44f76877e95da369f3fae"
          ]
        },
        "id": "tRYSlTNrgkJs",
        "outputId": "f0c0c625-cd37-4683-9b94-0c240591136b"
      },
      "source": [
        "initial_net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "initial_net = initial_net.to(device)\n",
        "torch.save(initial_net,'/content/init.pt')\n",
        "initial_net"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to _dataset/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80a314a1a2604204afdcf1e172bdd419",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting _dataset/cifar-10-python.tar.gz to _dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG_SNIP(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jNCk-s9i6G8"
      },
      "source": [
        "# Pruning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFIi-BL8vZMk"
      },
      "source": [
        "SNIP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c8pwhf7sbdy"
      },
      "source": [
        "def snip_forward_conv2d(self, x):\n",
        "        return F.conv2d(x, self.weight * self.weight_mask, self.bias,\n",
        "                        self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "\n",
        "def snip_forward_linear(self, x):\n",
        "        return F.linear(x, self.weight * self.weight_mask, self.bias)\n",
        "\n",
        "\n",
        "def SNIP(net, keep_ratio, train_dataloader, device):\n",
        "    # TODO: shuffle?\n",
        "\n",
        "    # Grab a single batch from the training dataset\n",
        "    inputs, targets = next(iter(train_dataloader))\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Let's create a fresh copy of the network so that we're not worried about\n",
        "    # affecting the actual training-phase\n",
        "    net = copy.deepcopy(net)\n",
        "\n",
        "    # Monkey-patch the Linear and Conv2d layer to learn the multiplicative mask\n",
        "    # instead of the weights\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight))\n",
        "            nn.init.xavier_normal_(layer.weight)\n",
        "            layer.weight.requires_grad = False\n",
        "\n",
        "        # Override the forward methods:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
        "\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            layer.forward = types.MethodType(snip_forward_linear, layer)\n",
        "\n",
        "    # Compute gradients (but don't apply them)\n",
        "    net.zero_grad()\n",
        "    outputs = net.forward(inputs)\n",
        "    loss = F.nll_loss(outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    grads_abs = []\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            grads_abs.append(torch.abs(layer.weight_mask.grad))\n",
        "\n",
        "    # Gather all scores in a single vector and normalise\n",
        "    all_scores = torch.cat([torch.flatten(x) for x in grads_abs])\n",
        "    norm_factor = torch.sum(all_scores)\n",
        "    all_scores.div_(norm_factor)\n",
        "\n",
        "    num_params_to_keep = int(len(all_scores) * keep_ratio)\n",
        "    threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\n",
        "    acceptable_score = threshold[-1]\n",
        "\n",
        "    keep_masks = []\n",
        "    for g in grads_abs:\n",
        "        keep_masks.append(((g / norm_factor) >= acceptable_score).float())\n",
        "        \n",
        "    print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\n",
        "\n",
        "    return (keep_masks)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLxN9Y0Ov2eD"
      },
      "source": [
        "def apply_prune_mask(net, keep_masks):\n",
        "\n",
        "    # Before I can zip() layers and pruning masks I need to make sure they match\n",
        "    # one-to-one by removing all the irrelevant modules:\n",
        "    prunable_layers = filter(\n",
        "        lambda layer: isinstance(layer, nn.Conv2d) or isinstance(\n",
        "            layer, nn.Linear), net.modules())\n",
        "\n",
        "    for layer, keep_mask in zip(prunable_layers, keep_masks):\n",
        "        assert (layer.weight.shape == keep_mask.shape)\n",
        "\n",
        "        def hook_factory(keep_mask):\n",
        "            \"\"\"\n",
        "            The hook function can't be defined directly here because of Python's\n",
        "            late binding which would result in all hooks getting the very last\n",
        "            mask! Getting it through another function forces early binding.\n",
        "            \"\"\"\n",
        "\n",
        "            def hook(grads):\n",
        "                return grads * keep_mask\n",
        "\n",
        "            return hook\n",
        "\n",
        "        # mask[i] == 0 --> Prune parameter\n",
        "        # mask[i] == 1 --> Keep parameter\n",
        "\n",
        "        # Step 1: Set the masked weights to zero (NB the biases are ignored)\n",
        "        # Step 2: Make sure their gradients remain zero\n",
        "        layer.weight.data[keep_mask == 0.] = 0.\n",
        "        layer.weight.register_hook(hook_factory(keep_mask))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF-FcEgVjbnY"
      },
      "source": [
        "# Pruning while training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbTQd0fYj38y"
      },
      "source": [
        "def training(epoch, model, optimizer, scheduler, criterion, device, train_loader):\n",
        "  model.train()\n",
        "  avg_loss = 0.0\n",
        "  av_loss=0.0\n",
        "  total=0\n",
        "  for batch_num, (feats, labels) in enumerate(train_loader):\n",
        "      feats, labels = feats.to(device), labels.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(feats)\n",
        "\n",
        "\n",
        "      loss = criterion(outputs, labels.long())\n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "      \n",
        "      avg_loss += loss.item()\n",
        "      av_loss += loss.item() \n",
        "      total +=len(feats) \n",
        "      # if batch_num % 10 == 9:\n",
        "      #     print('Epoch: {}\\tBatch: {}\\tAv-Loss: {:.4f}'.format(epoch+1, batch_num+1, av_loss/10))\n",
        "      #     av_loss = 0.0\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      del feats\n",
        "      del labels\n",
        "      del loss\n",
        "\n",
        "  del train_loader\n",
        "  return avg_loss/total"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhOefkNFwG3S"
      },
      "source": [
        "import time\n",
        "\n",
        "def validate(epoch, model, criterion, device, data_loader):\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        running_loss, accuracy,total  = 0.0, 0.0, 0\n",
        "\n",
        "        \n",
        "        for i, (X, Y) in enumerate(data_loader):\n",
        "            \n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            output= model(X)\n",
        "            loss = criterion(output, Y.long())\n",
        "\n",
        "            _,pred_labels = torch.max(F.softmax(output, dim=1), 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            \n",
        "            accuracy += torch.sum(torch.eq(pred_labels, Y)).item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total += len(X)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            del X\n",
        "            del Y\n",
        "        \n",
        "        return running_loss/total, accuracy/total, (time.time() - start_time)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJrAtHiArxhL"
      },
      "source": [
        "for _ in range(REPEAT_WITH_DIFFERENT_SEED):\n",
        "      after_pruning_net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "      after_pruning_net = after_pruning_net.to(device)\n",
        "      # Pre-training pruning using SKIP\n",
        "      keep_masks = SNIP(after_pruning_net, 0.05, train_loader, device)  # TODO: shuffle?\n",
        "      apply_prune_mask(after_pruning_net, keep_masks)\n",
        "      \n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "      for epoch in range(EPOCHS):\n",
        "          train_loss = training(epoch, after_pruning_net, optimiser, lr_scheduler, criterion, device,train_loader)\n",
        "\n",
        "          val_loss, val_acc = validate(epoch, after_pruning_net, criterion, device, val_loader)\n",
        "\n",
        "          lr_scheduler.step()\n",
        "\n",
        "          print('Epoch: {} \\t train-Loss: {:.4f}, \\tval-Loss: {:.4f}, \\tval-acc: {:.4f}'.format(epoch+1,  train_loss, val_loss, val_acc))\n",
        "\n",
        "      torch.save(after_pruning_net,checkpoint_loc+'depression_1.ptmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB9l6iFR7FzR"
      },
      "source": [
        "# torch.save(net,'/content/gdrive/MyDrive/11785/project/deep depression/after_pruning.ptmodel')\n",
        "after_pruning_net = torch.load('/content/gdrive/MyDrive/11785/project/deep depression/after_pruning.ptmodel')\n",
        "# net = torch.load('after_pruning.ptmodel')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6S3bwXnTpJ6v",
        "outputId": "36d6a962-90d4-4151-8f5a-42f1b0ea17aa"
      },
      "source": [
        " criterion = nn.CrossEntropyLoss()\n",
        " val_loss, val_acc,time_taken = validate(0, after_pruning_net, criterion, device, val_loader)\n",
        " print(val_loss, ' ', val_acc,' ',time_taken)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0022592162996530533   0.9193   2.5314345359802246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOb17YiRr0Dy"
      },
      "source": [
        "# Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAwR8XXd6Ik-"
      },
      "source": [
        "Sparse matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK3rMqHB9x3f",
        "outputId": "4001706d-fa9c-4e3e-e95a-20cbd520dd9a"
      },
      "source": [
        "import copy\n",
        "quantization_net = copy.deepcopy(after_pruning_net)\n",
        "quantization_net.features\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (5): ReLU(inplace=True)\n",
              "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (9): ReLU(inplace=True)\n",
              "  (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (12): ReLU(inplace=True)\n",
              "  (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (16): ReLU(inplace=True)\n",
              "  (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (19): ReLU(inplace=True)\n",
              "  (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (22): ReLU(inplace=True)\n",
              "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (26): ReLU(inplace=True)\n",
              "  (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (29): ReLU(inplace=True)\n",
              "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (32): ReLU(inplace=True)\n",
              "  (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (36): ReLU(inplace=True)\n",
              "  (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (39): ReLU(inplace=True)\n",
              "  (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (42): ReLU(inplace=True)\n",
              "  (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9rcx6D1dMch"
      },
      "source": [
        "Feature wide quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "4lIE0Qk66crJ",
        "outputId": "59fb446b-0aa4-4794-b4cc-5a472bf62b04"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "bits = 5\n",
        "for layer, (name, module) in enumerate(quantization_net.features._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    dev = module.weight.device\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    org_shape =  module.weight.shape\n",
        "\n",
        "    flatten_weights = weight.flatten()\n",
        "    min_ = np.min(flatten_weights)\n",
        "    max_ = np.max(flatten_weights)\n",
        "    space = np.linspace(min_, max_, num=2**bits)\n",
        "\n",
        "    print(module.weight.flatten().size())\n",
        "    kmeans = KMeans(n_clusters=len(space), init=space.reshape(-1,1), n_init=1, precompute_distances=True, algorithm=\"full\")\n",
        "    kmeans.fit(weight.reshape(-1,1))\n",
        "    new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(-1)\n",
        "    mat = new_weight.reshape(org_shape)\n",
        "    module.weight.data = torch.from_numpy(mat).to(dev)\n",
        "\n",
        "  else:\n",
        "    print('skipped')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------  name: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([1728])\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([64])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([36864])\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([64])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "torch.Size([73728])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-781dc2af00a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"full\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mnew_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m                     \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m                     x_squared_norms=x_squared_norms, random_state=seed)\n\u001b[0m\u001b[1;32m    938\u001b[0m                 \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_lloyd\u001b[0;34m(X, sample_weight, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    422\u001b[0m             _labels_inertia(X, sample_weight, x_squared_norms, centers,\n\u001b[1;32m    423\u001b[0m                             \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m                             distances=distances)\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;31m# computation of the means is also called the M-step of EM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_labels_inertia\u001b[0;34m(X, sample_weight, x_squared_norms, centers, precompute_distances, distances)\u001b[0m\n\u001b[1;32m    560\u001b[0m             return _labels_inertia_precompute_dense(X, sample_weight,\n\u001b[1;32m    561\u001b[0m                                                     \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m                                                     distances)\n\u001b[0m\u001b[1;32m    563\u001b[0m         inertia = _k_means._assign_labels_array(\n\u001b[1;32m    564\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_squared_norms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_labels_inertia_precompute_dense\u001b[0;34m(X, sample_weight, x_squared_norms, centers, distances)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;31m# TODO: Once PR #7383 is merged use check_inputs=False in metric_kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m     labels, mindist = pairwise_distances_argmin_min(\n\u001b[0;32m--> 499\u001b[0;31m         X=X, Y=centers, metric='euclidean', metric_kwargs={'squared': True})\n\u001b[0m\u001b[1;32m    500\u001b[0m     \u001b[0;31m# cython k-means code assumes int32 inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_argmin_min\u001b[0;34m(X, Y, axis, metric, metric_kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     indices, values = zip(*pairwise_distances_chunked(\n\u001b[1;32m    584\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_argmin_min_reduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         **metric_kwargs))\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1593\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1595\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1596\u001b[0m         if ((X is Y or Y is None)\n\u001b[1;32m   1597\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1750\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# To minimize precision issues with float32, we compute the distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# matrix on chunks of X and Y upcast to float64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_euclidean_distances_upcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_euclidean_distances_upcast\u001b[0;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mXX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0my_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOppJhK-dR7w"
      },
      "source": [
        "Classifier quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rifao3XedRas",
        "outputId": "21b15772-d383-4d01-802c-b528e1645994"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "bits = 5\n",
        "for layer, (name, module) in enumerate(quantization_net.classifier._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    dev = module.weight.device\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    org_shape =  module.weight.shape\n",
        "\n",
        "    flatten_weights = weight.flatten()\n",
        "    min_ = np.min(flatten_weights)\n",
        "    max_ = np.max(flatten_weights)\n",
        "    space = np.linspace(min_, max_, num=2**bits)\n",
        "\n",
        "    print(module.weight.flatten().size())\n",
        "    kmeans = KMeans(n_clusters=len(space), init=space.reshape(-1,1), n_init=1, precompute_distances=True, algorithm=\"full\")\n",
        "    kmeans.fit(weight.reshape(-1,1))\n",
        "    new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(-1)\n",
        "    mat = new_weight.reshape(org_shape)\n",
        "    module.weight.data = torch.from_numpy(mat).to(dev)\n",
        "\n",
        "  else:\n",
        "    print('skipped')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------  name: Linear(in_features=512, out_features=512, bias=True)\n",
            "torch.Size([262144])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: Linear(in_features=512, out_features=512, bias=True)\n",
            "torch.Size([262144])\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "torch.Size([512])\n",
            "----------  name: Linear(in_features=512, out_features=10, bias=True)\n",
            "torch.Size([5120])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7v5Z0VIn35f"
      },
      "source": [
        "quantization_net = torch.load('/content/gdrive/MyDrive/11785/project/deep depression/after_quantization.ptmodel')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ8Qx_gQUN_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37d00224-f996-4632-fba3-da4cca0d7b67"
      },
      "source": [
        " quantization_net.cuda()\n",
        " val_loss, val_acc,time_taken = validate(0, quantization_net, criterion, device, val_loader)\n",
        " print(val_acc,' ',time_taken)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9184   2.3771140575408936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf6CsKV-a_5r"
      },
      "source": [
        "torch.save(quantization_net,'after_quantization.ptmodel')\n",
        "torch.save(quantization_net,'/content/gdrive/MyDrive/11785/project/deep depression/after_quantization.ptmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KoYVGtRgAjY"
      },
      "source": [
        "# Post quantization comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l8LUpKcgHfi",
        "outputId": "7aa146f9-a71c-40e2-e56d-74278ddda473"
      },
      "source": [
        "layer_names = []\n",
        "post_quant_weights_unique = []\n",
        "for layer, (name, module) in enumerate(quantization_net.features._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    flatten_weights = weight.flatten()\n",
        "    layer_names.append(module.__class__.__name__)\n",
        "    post_quant_weights_unique.append(np.unique(flatten_weights))\n",
        "  else:\n",
        "    print('skipped')\n",
        "for layer, (name, module) in enumerate(quantization_net.classifier._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    flatten_weights = weight.flatten()\n",
        "    layer_names.append(module.__class__.__name__)\n",
        "    post_quant_weights_unique.append(np.unique(flatten_weights))\n",
        "  else:\n",
        "    print('skipped')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------  name: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Linear(in_features=512, out_features=512, bias=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: Linear(in_features=512, out_features=512, bias=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: Linear(in_features=512, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evavO9Yyhk_W",
        "outputId": "2ed8f89b-cb2a-4221-d6d1-526285436d84"
      },
      "source": [
        "layer_names = []\n",
        "pre_quant_weights_unique = []\n",
        "for layer, (name, module) in enumerate(after_pruning_net.features._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    flatten_weights = weight.flatten()\n",
        "    layer_names.append(module.__class__.__name__)\n",
        "    pre_quant_weights_unique.append(np.unique(flatten_weights))\n",
        "  else:\n",
        "    print('skipped')\n",
        "for layer, (name, module) in enumerate(after_pruning_net.classifier._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    flatten_weights = weight.flatten()\n",
        "    layer_names.append(module.__class__.__name__)\n",
        "    pre_quant_weights_unique.append(np.unique(flatten_weights))\n",
        "  else:\n",
        "    print('skipped')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------  name: Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "----------  name: BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "skipped\n",
            "----------  name: Linear(in_features=512, out_features=512, bias=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: Linear(in_features=512, out_features=512, bias=True)\n",
            "----------  name: ReLU(inplace=True)\n",
            "skipped\n",
            "----------  name: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "----------  name: Linear(in_features=512, out_features=10, bias=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTdU5A6Bhqdj",
        "outputId": "ec5ba043-5f3f-469e-9844-3a0db9863ac5"
      },
      "source": [
        "if len(post_quant_weights_unique) == len(pre_quant_weights_unique):\n",
        "  print('true')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "true\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MshoAHLlh-Yf",
        "outputId": "f149c75e-8580-46e7-f738-16213527ba78"
      },
      "source": [
        "i = 0\n",
        "for old_w,new_w in zip(pre_quant_weights_unique,post_quant_weights_unique):\n",
        "  print('layer_names [',layer_names[i],'] -> unique weights count old:',len(old_w),', new:',len(new_w))\n",
        "  i+=1"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer_names [ Conv2d ] -> unique weights count old: 1590 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 64 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 26883 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 64 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 47853 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 128 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 76178 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 128 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 111327 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 256 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 133452 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 256 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 108554 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 256 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 97934 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 512 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 55523 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 512 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 32482 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 512 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 29773 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 507 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 18410 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 507 , new: 32\n",
            "layer_names [ Conv2d ] -> unique weights count old: 11140 , new: 32\n",
            "layer_names [ BatchNorm2d ] -> unique weights count old: 497 , new: 32\n",
            "layer_names [ Linear ] -> unique weights count old: 8298 , new: 32\n",
            "layer_names [ BatchNorm1d ] -> unique weights count old: 235 , new: 32\n",
            "layer_names [ Linear ] -> unique weights count old: 874 , new: 32\n",
            "layer_names [ BatchNorm1d ] -> unique weights count old: 236 , new: 32\n",
            "layer_names [ Linear ] -> unique weights count old: 1318 , new: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtimKpFLivqb"
      },
      "source": [
        "# casting post quantize weights to int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_Mb2lj_i13p"
      },
      "source": [
        "import copy\n",
        "post_process_net = torch.load('/content/gdrive/MyDrive/11785/project/deep depression/after_quantization.ptmodel')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqiPR3hpkfCB",
        "outputId": "03ef49d9-e245-4469-e48c-5d059d0c3543"
      },
      "source": [
        " val_loss, val_acc,time_taken = validate(0, post_process_net, criterion, device, val_loader)\n",
        " print(val_acc,time_taken)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9186 6.498332977294922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp2Vxo95sTGZ",
        "outputId": "1b1d975e-8a39-4675-e004-818ac56a095d"
      },
      "source": [
        "import torch.quantization\n",
        "post_process_net = post_process_net.to('cpu')\n",
        "device='cpu'\n",
        "post_process_net.qconfig = torch.quantization.default_qconfig\n",
        "torch.quantization.prepare(post_process_net, inplace=True)\n",
        "torch.quantization.convert(post_process_net, inplace=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:245: UserWarning: must run observer before calling calculate_qparams.                                        Returning default scale and zero point \n",
            "  Returning default scale and zero point \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG_SNIP(\n",
              "  (features): Sequential(\n",
              "    (0): QuantizedConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (1): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (4): QuantizedBatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (8): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (11): QuantizedBatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (15): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (18): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (21): QuantizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (25): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (28): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (31): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (35): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (38): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "    (41): QuantizedBatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): QuantizedLinear(in_features=512, out_features=512, scale=1.0, zero_point=0, qscheme=torch.per_tensor_affine)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): QuantizedLinear(in_features=512, out_features=512, scale=1.0, zero_point=0, qscheme=torch.per_tensor_affine)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): QuantizedLinear(in_features=512, out_features=10, scale=1.0, zero_point=0, qscheme=torch.per_tensor_affine)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX5fFT8VtblS"
      },
      "source": [
        " post_process_net.cpu()\n",
        " val_loss, val_acc,time_taken = validate(0, post_process_net, criterion, device, val_loader)\n",
        " print(val_acc,time_taken)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCnrWzHUkoDa"
      },
      "source": [
        "torch.save(net,'after_quantization_int.ptmodel')\n",
        "torch.save(net,'/content/gdrive/MyDrive/11785/project/deep depression/after_quantization_int.ptmodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edv2T9WoknND"
      },
      "source": [
        "# post int quantize weights comparison with quantize weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckHlXdItkzB-"
      },
      "source": [
        "layer_names = []\n",
        "post_quant_weights_int_unique = []\n",
        "for layer, (name, module) in enumerate(net.features._modules.items()):\n",
        "  print('-'*10,' name:', module)\n",
        "  if not isinstance(module,nn.ReLU) and not isinstance(module,nn.MaxPool2d):\n",
        "    weight = module.weight.data.cpu().numpy()\n",
        "    flatten_weights = weight.flatten()\n",
        "    post_quant_weights_int_unique.append(np.unique(flatten_weights))\n",
        "  else:\n",
        "    print('skipped')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPbyqL1EkVpw"
      },
      "source": [
        "# Visualization convolution weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUGx-cxCkepO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_filters_multi_channel(t,img_name):\n",
        "    \n",
        "    #get the number of kernals\n",
        "    num_kernels = t.shape[0]    \n",
        "    \n",
        "    #define number of columns for subplots\n",
        "    num_cols = 12\n",
        "    #rows = num of kernels\n",
        "    num_rows = num_kernels\n",
        "    \n",
        "    #set the figure size\n",
        "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
        "    \n",
        "    #looping through all the kernels\n",
        "    for i in range(t.shape[0]):\n",
        "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
        "        \n",
        "        #for each kernel, we convert the tensor to numpy \n",
        "        npimg = np.array(t[i].numpy(), np.float32)\n",
        "        #standardize the numpy image\n",
        "        npimg = (npimg - np.mean(npimg)) / np.std(npimg)\n",
        "        npimg = np.minimum(1, np.maximum(0, (npimg + 0.5)))\n",
        "        npimg = npimg.transpose((1, 2, 0))\n",
        "        ax1.imshow(npimg)\n",
        "        ax1.axis('off')\n",
        "        ax1.set_title(str(i))\n",
        "        ax1.set_xticklabels([])\n",
        "        ax1.set_yticklabels([])\n",
        "        \n",
        "    plt.savefig(img_name, dpi=100)    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49U4g30moi9m"
      },
      "source": [
        "def plot_weights(model, layer_num,img_name):\n",
        "  \n",
        "  layer = model.features[layer_num]\n",
        "  \n",
        "  if isinstance(layer, nn.Conv2d):\n",
        "    weight_tensor = model.features[layer_num].weight.data\n",
        "    if weight_tensor.shape[1] == 3:\n",
        "      plot_filters_multi_channel(weight_tensor,img_name)\n",
        "    else:\n",
        "        print(\"Can only plot weights with three channels with single channel = False\")     \n",
        "  else:\n",
        "    print(\"Can only visualize layers which are convolutional\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRLTBRGHozl1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "initial_net = initial_net.to('cpu')\n",
        "after_pruning_net = after_pruning_net.to('cpu')\n",
        "quantization_net = quantization_net.to('cpu')\n",
        "plot_weights(initial_net, 0,'initial state of weights')\n",
        "plot_weights(after_pruning_net, 0,'after pruning')\n",
        "plot_weights(quantization_net, 0,'after quantization with k-means')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5pm7_XWQptW"
      },
      "source": [
        "# Visualization Activation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "mjsmyyZCQysW",
        "outputId": "e0d2e267-b975-4c76-a281-678bed00c318"
      },
      "source": [
        "print(quantization_net.classifier[0])\n",
        "quantization_net = quantization_net.to('cpu')\n",
        "print(np.unique(quantization_net.classifier[0].weight.data.flatten()))\n",
        "plt.imshow(quantization_net.classifier[0].weight.data)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Linear(in_features=512, out_features=512, bias=True)\n",
            "[-2.62651205e-01 -2.00239673e-01 -1.52694285e-01 -1.30984098e-01\n",
            " -1.11580133e-01 -9.03302729e-02 -6.05782866e-02 -4.06768061e-02\n",
            " -2.74116416e-02 -1.84960216e-02 -1.17350705e-02 -5.85467555e-03\n",
            " -2.37078825e-03 -6.54769887e-04  2.78642801e-06  2.29578675e-03\n",
            "  6.95845997e-03  1.36291971e-02  2.15460546e-02  3.15798894e-02\n",
            "  4.34518382e-02  5.56850210e-02  6.92472532e-02  7.85576776e-02\n",
            "  9.07434896e-02  1.12685129e-01  1.39182061e-01  1.52690858e-01\n",
            "  1.75977081e-01  1.93883166e-01  2.74437904e-01  4.24591839e-01]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3108f54150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}