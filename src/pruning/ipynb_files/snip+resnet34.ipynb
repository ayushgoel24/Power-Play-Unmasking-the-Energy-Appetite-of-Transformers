{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snip+resnet34.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI-oLU4e7tt4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "\n",
        "#from tensorboardX import SummaryWriter\n",
        "#from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
        "#from ignite.metrics import Accuracy, Loss\n",
        "#from ignite.contrib.handlers import ProgressBar\n",
        "\n",
        "#from snip import SNIP\n",
        "import copy\n",
        "import types"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkEc3pBV7_1d"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "LOG_INTERVAL = 20\n",
        "INIT_LR = 0.1\n",
        "WEIGHT_DECAY_RATE = 0.0005\n",
        "EPOCHS = 70\n",
        "REPEAT_WITH_DIFFERENT_SEED = 1"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdlVLd6c8A9I",
        "outputId": "a6f5785c-6086-46f0-85d9-bcdf9aeacb45"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_KM6Zir8Dbu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "88418202-e536-4269-e5c2-8c3879d72d7f"
      },
      "source": [
        "def snip_forward_conv2d(self, x):\n",
        "        return F.conv2d(x, self.weight * self.weight_mask, self.bias,\n",
        "                        self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "\n",
        "def snip_forward_linear(self, x):\n",
        "        return F.linear(x, self.weight * self.weight_mask, self.bias)\n",
        "\n",
        "\n",
        "\"\"\"def SNIP(net, keep_ratio, train_dataloader, device):\n",
        "    # TODO: shuffle?\n",
        "\n",
        "    # Grab a single batch from the training dataset\n",
        "    inputs, targets = next(iter(train_dataloader))\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    # Let's create a fresh copy of the network so that we're not worried about\n",
        "    # affecting the actual training-phase\n",
        "    net = copy.deepcopy(net)\n",
        "\n",
        "    # Monkey-patch the Linear and Conv2d layer to learn the multiplicative mask\n",
        "    # instead of the weights\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight))\n",
        "            nn.init.xavier_normal_(layer.weight)\n",
        "            layer.weight.requires_grad = False\n",
        "\n",
        "        # Override the forward methods:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
        "\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            layer.forward = types.MethodType(snip_forward_linear, layer)\n",
        "\n",
        "    # Compute gradients (but don't apply them)\n",
        "    net.zero_grad()\n",
        "    outputs = net.forward(inputs)\n",
        "    loss = F.nll_loss(outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    grads_abs = []\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            grads_abs.append(torch.abs(layer.weight_mask.grad))\n",
        "\n",
        "    # Gather all scores in a single vector and normalise\n",
        "    all_scores = torch.cat([torch.flatten(x) for x in grads_abs])\n",
        "    norm_factor = torch.sum(all_scores)\n",
        "    all_scores.div_(norm_factor)\n",
        "\n",
        "    num_params_to_keep = int(len(all_scores) * keep_ratio)\n",
        "    threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\n",
        "    acceptable_score = threshold[-1]\n",
        "\n",
        "    keep_masks = []\n",
        "    for g in grads_abs:\n",
        "        keep_masks.append(((g / norm_factor) >= acceptable_score).float())\n",
        "        \n",
        "    print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\n",
        "\n",
        "    return (keep_masks)\"\"\""
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"def SNIP(net, keep_ratio, train_dataloader, device):\\n    # TODO: shuffle?\\n\\n    # Grab a single batch from the training dataset\\n    inputs, targets = next(iter(train_dataloader))\\n    inputs = inputs.to(device)\\n    targets = targets.to(device)\\n\\n    # Let's create a fresh copy of the network so that we're not worried about\\n    # affecting the actual training-phase\\n    net = copy.deepcopy(net)\\n\\n    # Monkey-patch the Linear and Conv2d layer to learn the multiplicative mask\\n    # instead of the weights\\n    for layer in net.modules():\\n        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\\n            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight))\\n            nn.init.xavier_normal_(layer.weight)\\n            layer.weight.requires_grad = False\\n\\n        # Override the forward methods:\\n        if isinstance(layer, nn.Conv2d):\\n            layer.forward = types.MethodType(snip_forward_conv2d, layer)\\n\\n        if isinstance(layer, nn.Linear):\\n            layer.forward = types.MethodType(snip_forward_linear, layer)\\n\\n    # Compute gradients (but don't apply them)\\n    net.zero_grad()\\n    outputs = net.forward(inputs)\\n    loss = F.nll_loss(outputs, targets)\\n    loss.backward()\\n\\n    grads_abs = []\\n    for layer in net.modules():\\n        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\\n            grads_abs.append(torch.abs(layer.weight_mask.grad))\\n\\n    # Gather all scores in a single vector and normalise\\n    all_scores = torch.cat([torch.flatten(x) for x in grads_abs])\\n    norm_factor = torch.sum(all_scores)\\n    all_scores.div_(norm_factor)\\n\\n    num_params_to_keep = int(len(all_scores) * keep_ratio)\\n    threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\\n    acceptable_score = threshold[-1]\\n\\n    keep_masks = []\\n    for g in grads_abs:\\n        keep_masks.append(((g / norm_factor) >= acceptable_score).float())\\n        \\n    print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\\n\\n    return (keep_masks)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5Bqzp2TlzUJ"
      },
      "source": [
        "def SNIP_mask_add(net):\n",
        "    # TODO: shuffle?\n",
        "\n",
        "    #net = copy.deepcopy(net)\n",
        "\n",
        "    #grads_abs = []\n",
        "\n",
        "    for layer in net.modules():\n",
        "  
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight))\n",
        "            #nn.init.xavier_normal_(layer.weight)\n",
        "            #layer.weight.requires_grad = False\n",
        "            #print(\"abcd\")\n",
        "            #print(layer.weight_mask)\n",
        "\n",
        "        # Override the forward methods:\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
        "\n",
        "        if isinstance(layer, nn.Linear):\n",
        "            layer.forward = types.MethodType(snip_forward_linear, layer)\n",
        "\n",
        "\n",
        "# def SNIP_mask_quantize(net, keep_ratio):\n",
        "#     grads_abs=[]\n",
        "#     for layer in net.modules():\n",
        "#         if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "#             grads_abs.append(torch.abs(layer.weight_mask.grad))\n",
        "\n",
        "#     # Gather all scores in a single vector and normalise\n",
        "#     all_scores = torch.cat([torch.flatten(x) for x in grads_abs])\n",
        "#     norm_factor = torch.sum(all_scores)\n",
        "#     all_scores.div_(norm_factor)\n",
        "\n",
        "#     num_params_to_keep = int(len(all_scores) * keep_ratio)\n",
        "#     threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\n",
        "#     acceptable_score = threshold[-1]\n",
        "\n",
        "#     keep_masks = []\n",
        "#     for g in grads_abs:\n",
        "#         keep_masks.append(((g / norm_factor) >= acceptable_score).float())\n",
        "        \n",
        "#     #print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\n",
        "#     #print(len(keep_masks))\n",
        "#     return (keep_masks)\n",
        "\n",
        "def SNIP_mask_quantize(net, keep_ratio):\n",
        "    #grads_abs=[]\n",
        "    layer_num=0\n",
        "    keep_masks = []\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "            grads_abs = torch.abs(layer.weight_mask.grad)\n",
        "\n",
        "            # Gather all scores in a single vector and normalise\n",
        "            all_scores = torch.flatten(grads_abs) \n",
        "            norm_factor = torch.sum(all_scores)\n",
        "            all_scores.div_(norm_factor)\n",
        "\n",
        "            num_params_to_keep = int(len(all_scores) * keep_ratio[layer_num])\n",
        "            threshold, _ = torch.topk(all_scores, num_params_to_keep, sorted=True)\n",
        "            acceptable_score = threshold[-1]\n",
        "            \n",
        "\n",
        "            #for g in grads_abs:\n",
        "            #g = grad_abs\n",
        "            keep_masks.append(((grads_abs / norm_factor) >= acceptable_score).float())\n",
        "            #print(grads_abs.shape, all_scores.shape, layer_num, num_params_to_keep, acceptable_score, norm_factor)\n",
        "            layer_num +=1\n",
        "            #print(torch.sum(torch.cat([torch.flatten(x == 1) for x in keep_masks])))\n",
        "\n",
        "    return (keep_masks)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULm6Wjt58KTa"
      },
      "source": [
        "# def apply_prune_mask(net, keep_masks):\n",
        "\n",
        "#     # Before I can zip() layers and pruning masks I need to make sure they match\n",
        "#     # one-to-one by removing all the irrelevant modules:\n",
        "#     prunable_layers = filter(\n",
        "#         lambda layer: isinstance(layer, nn.Conv2d) or isinstance(\n",
        "#             layer, nn.Linear), net.modules())\n",
        "\n",
        "#     for layer, keep_mask in zip(prunable_layers, keep_masks):\n",
        "#         assert (layer.weight.shape == keep_mask.shape)\n",
        "\n",
        "#         def hook_factory(keep_mask):\n",
        "#             \"\"\"\n",
        "#             The hook function can't be defined directly here because of Python's\n",
        "#             late binding which would result in all hooks getting the very last\n",
        "#             mask! Getting it through another function forces early binding.\n",
        "#             \"\"\"\n",
        "\n",
        "#             def hook(grads):\n",
        "#                 return grads * keep_mask\n",
        "\n",
        "#             return hook\n",
        "\n",
        "#         # mask[i] == 0 --> Prune parameter\n",
        "#         # mask[i] == 1 --> Keep parameter\n",
        "\n",
        "#         # Step 1: Set the masked weights to zero (NB the biases are ignored)\n",
        "#         # Step 2: Make sure their gradients remain zero\n",
        "#         layer.weight.data[keep_mask == 0.] = 0.\n",
        "#         layer.weight.register_hook(hook_factory(keep_mask))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggkjQer1sLZn"
      },
      "source": [
        "def apply_prune_mask(net, keep_masks):\n",
        "\n",
        "    # Before I can zip() layers and pruning masks I need to make sure they match\n",
        "    # one-to-one by removing all the irrelevant modules:\n",
        "    prunable_layers = filter(\n",
        "        lambda layer: isinstance(layer, nn.Conv2d) or isinstance(\n",
        "            layer, nn.Linear), net.modules())\n",
        "\n",
        "    for layer, keep_mask in zip(prunable_layers, keep_masks):\n",
        "        assert (layer.weight.shape == keep_mask.shape)\n",
        "\n",
        "        def hook_factory(keep_mask):\n",
        "            \"\"\"\n",
        "            The hook function can't be defined directly here because of Python's\n",
        "            late binding which would result in all hooks getting the very last\n",
        "            mask! Getting it through another function forces early binding.\n",
        "            \"\"\"\n",
        "\n",
        "            def hook(grads):\n",
        "                return grads * keep_mask\n",
        "\n",
        "            return hook\n",
        "\n",
        "        # mask[i] == 0 --> Prune parameter\n",
        "        # mask[i] == 1 --> Keep parameter\n",
        "\n",
        "        # Step 1: Set the masked weights to zero (NB the biases are ignored)\n",
        "        # Step 2: Make sure their gradients remain zero\n",
        "        layer.weight.data[keep_mask == 0.] = 0.\n",
        "        #layer.weight.register_hook(hook_factory(keep_mask))"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSPbHdYp8K6d"
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, base_width=1, padding=1, batch_norm=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if batch_norm is None:\n",
        "            bn_layer = nn.Batchnorm2D\n",
        "        else:\n",
        "            bn_layer = batch_norm\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=padding, bias=False)\n",
        "        self.bn1 = bn_layer(out_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, bias=False)\n",
        "        self.bn2 = bn_layer(out_channels)\n",
        "\n",
        "        self.downsample = downsample\n",
        "        if self.downsample is None:\n",
        "            self.shortcut = nn.Identity()\n",
        "        else:\n",
        "            self.shortcut = self.downsample\n",
        "\n",
        "        self.stride = stride\n",
        "\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet34(nn.Module):\n",
        "\n",
        "    def __init__(self, layers, num_classes=10, zero_init_residual=False, base_width=64, batch_norm=None):\n",
        "        # def make_layer(self, block, planes, blocks, stride= 1, dilate = False):\n",
        "        super(ResNet34, self).__init__()\n",
        "        block = BasicBlock\n",
        "        if batch_norm is None:\n",
        "            bn_layer = nn.BatchNorm2d\n",
        "        self.bn_layer = bn_layer\n",
        "\n",
        "        self.conv_out_channels = 64\n",
        "        self.in_channels = self.conv_out_channels\n",
        "        self.base_width = base_width\n",
        "        self.conv1 = nn.Conv2d(3, self.conv_out_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = bn_layer(self.conv_out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self.container(block, 64, layers[0])\n",
        "        self.layer2 = self.container(block, 128, layers[1], stride=2, dilate=False)\n",
        "        self.layer3 = self.container(block, 256, layers[2], stride=2, dilate=False)\n",
        "        self.layer4 = self.container(block, 512, layers[3], stride=2, dilate=False)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                #nn.init.xavier_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def container(self, block, in_channels, num_basicblocks, stride=1, dilate=False):\n",
        "        bn_layer = self.bn_layer\n",
        "        downsample = None\n",
        "        if stride != 1:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, in_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                bn_layer(in_channels),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(self.in_channels, in_channels, stride, downsample, self.base_width, padding=1, batch_norm=bn_layer))\n",
        "        self.in_channels = in_channels\n",
        "        for basic_blocks in range(1, num_basicblocks):\n",
        "            layers.append(block(self.in_channels, in_channels, base_width=self.base_width, batch_norm=bn_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIvg3mK6RFnu"
      },
      "source": [
        "def get_cifar10_dataloaders(train_batch_size, test_batch_size):\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                             (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10('_dataset', True, train_transform, download=True)\n",
        "    test_dataset = CIFAR10('_dataset', False, test_transform, download=False)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        test_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1twTvZ5RI8A"
      },
      "source": [
        "def cifar10_experiment():\n",
        "    \n",
        "    BATCH_SIZE = 128\n",
        "    LR_DECAY_INTERVAL = 20\n",
        "    \n",
        "    #net = VGG_SNIP('D').to(device)\n",
        "    net = ResNet34([3, 4, 6, 3])\n",
        "    #print(net)\n",
        "    optimiser = optim.SGD(\n",
        "        net.parameters(),\n",
        "        lr=INIT_LR,\n",
        "        momentum=0.9,\n",
        "        weight_decay=WEIGHT_DECAY_RATE)\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(\n",
        "        optimiser, LR_DECAY_INTERVAL, gamma=0.1)\n",
        "    \n",
        "    train_loader, val_loader = get_cifar10_dataloaders(BATCH_SIZE,\n",
        "                                                       BATCH_SIZE)  # TODO\n",
        "\n",
        "    return net, optimiser, lr_scheduler, train_loader, val_loader"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxL3nlg-RMoL"
      },
      "source": [
        "def training(epoch, model, optimizer, scheduler, criterion, device, train_loader):\n",
        "  model.train()\n",
        "  avg_loss = 0.0\n",
        "  av_loss=0.0\n",
        "  total=0\n",
        "  for batch_num, (feats, labels) in enumerate(train_loader):\n",
        "      feats, labels = feats.to(device), labels.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(feats)\n",
        "\n",
        "\n",
        "      loss = criterion(outputs, labels.long())\n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "      \n",
        "      avg_loss += loss.item()\n",
        "      av_loss += loss.item() \n",
        "      total +=len(feats) \n",
        "      # if batch_num % 10 == 9:\n",
        "      #     print('Epoch: {}\\tBatch: {}\\tAv-Loss: {:.4f}'.format(epoch+1, batch_num+1, av_loss/10))\n",
        "      #     av_loss = 0.0\n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      del feats\n",
        "      del labels\n",
        "      del loss\n",
        "\n",
        "  del train_loader\n",
        "\n",
        "  return avg_loss/total\n",
        "  "
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY8fgwrIRQEm"
      },
      "source": [
        "def validate(epoch, model, criterion, device, data_loader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        running_loss, accuracy,total  = 0.0, 0.0, 0\n",
        "\n",
        "        \n",
        "        for i, (X, Y) in enumerate(data_loader):\n",
        "            \n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            output= model(X)\n",
        "            loss = criterion(output, Y.long())\n",
        "\n",
        "            _,pred_labels = torch.max(F.softmax(output, dim=1), 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            \n",
        "            accuracy += torch.sum(torch.eq(pred_labels, Y)).item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total += len(X)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            del X\n",
        "            del Y\n",
        "        \n",
        "        return running_loss/total, accuracy/total"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a9hmhcaRQ1r"
      },
      "source": [
        "\"\"\"def train():\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "\n",
        "    # Pre-training pruning using SKIP\n",
        "    keep_masks = SNIP(net, 0.05, train_loader, device)  # TODO: shuffle?\n",
        "    apply_prune_mask(net, keep_masks)\"\"\""
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKuggE1YexRs"
      },
      "source": [
        "lr_scheduler = optim.lr_scheduler.StepLR(\n",
        "        optimiser, 20, gamma=0.1)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNnI26UhRUbZ",
        "outputId": "29d6ddca-5a1c-4a8d-e7ce-eabd6e864b02"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    for _ in range(REPEAT_WITH_DIFFERENT_SEED):\n",
        "      #train()\n",
        "      net, optimiser, lr_scheduler, train_loader, val_loader = cifar10_experiment()\n",
        "      net = net.to(device)\n",
        "      # Pre-training pruning using SKIP\n",
        "      #keep_masks = SNIP(net, 0.01, train_loader, device)  # TODO: shuffle?\n",
        "      #apply_prune_mask(net, keep_masks)\n",
        "      keep_ratio = [1] * 37\n",
        "      #keep_ratio=0.05\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "      for epoch in range(EPOCHS):\n",
        "         
        "          SNIP_mask_add(net)\n",
        "\n",
        "          train_loss = training(epoch, net, optimiser, lr_scheduler, criterion, device,train_loader)\n",
        "\n",
        "          val_loss, val_acc = validate(epoch, net, criterion, device, val_loader)\n",
        "\n",
        "          lr_scheduler.step()\n",
        "\n",
        "          keep_masks = SNIP_mask_quantize(net, keep_ratio)  # TODO: shuffle?\n",
        "          apply_prune_mask(net, keep_masks)\n",
        "\n",
        "          #print(net.layer[0], net.layer[0].weight.shape)\n",
        "          print('Epoch: {} \\t train-Loss: {:.4f}, \\tval-Loss: {:.4f}, \\tval-acc: {:.4f}'.format(epoch+1,  train_loss, val_loss, val_acc))\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch: 1 \t train-Loss: 0.0188, \tval-Loss: 0.0139, \tval-acc: 0.3481\n",
            "Epoch: 2 \t train-Loss: 0.0130, \tval-Loss: 0.0127, \tval-acc: 0.4081\n",
            "Epoch: 3 \t train-Loss: 0.0118, \tval-Loss: 0.0112, \tval-acc: 0.4808\n",
            "Epoch: 4 \t train-Loss: 0.0108, \tval-Loss: 0.0099, \tval-acc: 0.5446\n",
            "Epoch: 5 \t train-Loss: 0.0098, \tval-Loss: 0.0095, \tval-acc: 0.5717\n",
            "Epoch: 6 \t train-Loss: 0.0092, \tval-Loss: 0.0100, \tval-acc: 0.5522\n",
            "Epoch: 7 \t train-Loss: 0.0086, \tval-Loss: 0.0086, \tval-acc: 0.6216\n",
            "Epoch: 8 \t train-Loss: 0.0082, \tval-Loss: 0.0103, \tval-acc: 0.5817\n",
            "Epoch: 9 \t train-Loss: 0.0078, \tval-Loss: 0.0072, \tval-acc: 0.6880\n",
            "Epoch: 10 \t train-Loss: 0.0075, \tval-Loss: 0.0086, \tval-acc: 0.6303\n",
            "Epoch: 11 \t train-Loss: 0.0073, \tval-Loss: 0.0078, \tval-acc: 0.6588\n",
            "Epoch: 12 \t train-Loss: 0.0071, \tval-Loss: 0.0072, \tval-acc: 0.6876\n",
            "Epoch: 13 \t train-Loss: 0.0070, \tval-Loss: 0.0068, \tval-acc: 0.7043\n",
            "Epoch: 14 \t train-Loss: 0.0068, \tval-Loss: 0.0077, \tval-acc: 0.6753\n",
            "Epoch: 15 \t train-Loss: 0.0067, \tval-Loss: 0.0075, \tval-acc: 0.6775\n",
            "Epoch: 16 \t train-Loss: 0.0065, \tval-Loss: 0.0077, \tval-acc: 0.6782\n",
            "Epoch: 17 \t train-Loss: 0.0065, \tval-Loss: 0.0074, \tval-acc: 0.6876\n",
            "Epoch: 18 \t train-Loss: 0.0063, \tval-Loss: 0.0071, \tval-acc: 0.7013\n",
            "Epoch: 19 \t train-Loss: 0.0063, \tval-Loss: 0.0079, \tval-acc: 0.6632\n",
            "Epoch: 20 \t train-Loss: 0.0062, \tval-Loss: 0.0065, \tval-acc: 0.7168\n",
            "Epoch: 21 \t train-Loss: 0.0047, \tval-Loss: 0.0044, \tval-acc: 0.8044\n",
            "Epoch: 22 \t train-Loss: 0.0042, \tval-Loss: 0.0043, \tval-acc: 0.8121\n",
            "Epoch: 23 \t train-Loss: 0.0040, \tval-Loss: 0.0042, \tval-acc: 0.8136\n",
            "Epoch: 24 \t train-Loss: 0.0039, \tval-Loss: 0.0041, \tval-acc: 0.8167\n",
            "Epoch: 25 \t train-Loss: 0.0038, \tval-Loss: 0.0041, \tval-acc: 0.8206\n",
            "Epoch: 26 \t train-Loss: 0.0036, \tval-Loss: 0.0041, \tval-acc: 0.8198\n",
            "Epoch: 27 \t train-Loss: 0.0036, \tval-Loss: 0.0039, \tval-acc: 0.8312\n",
            "Epoch: 28 \t train-Loss: 0.0035, \tval-Loss: 0.0040, \tval-acc: 0.8251\n",
            "Epoch: 29 \t train-Loss: 0.0034, \tval-Loss: 0.0040, \tval-acc: 0.8232\n",
            "Epoch: 30 \t train-Loss: 0.0034, \tval-Loss: 0.0039, \tval-acc: 0.8299\n",
            "Epoch: 31 \t train-Loss: 0.0033, \tval-Loss: 0.0039, \tval-acc: 0.8326\n",
            "Epoch: 32 \t train-Loss: 0.0033, \tval-Loss: 0.0040, \tval-acc: 0.8314\n",
            "Epoch: 33 \t train-Loss: 0.0032, \tval-Loss: 0.0040, \tval-acc: 0.8310\n",
            "Epoch: 34 \t train-Loss: 0.0032, \tval-Loss: 0.0038, \tval-acc: 0.8356\n",
            "Epoch: 35 \t train-Loss: 0.0031, \tval-Loss: 0.0039, \tval-acc: 0.8290\n",
            "Epoch: 36 \t train-Loss: 0.0031, \tval-Loss: 0.0039, \tval-acc: 0.8329\n",
            "Epoch: 37 \t train-Loss: 0.0031, \tval-Loss: 0.0042, \tval-acc: 0.8222\n",
            "Epoch: 38 \t train-Loss: 0.0030, \tval-Loss: 0.0043, \tval-acc: 0.8206\n",
            "Epoch: 39 \t train-Loss: 0.0030, \tval-Loss: 0.0042, \tval-acc: 0.8200\n",
            "Epoch: 40 \t train-Loss: 0.0029, \tval-Loss: 0.0041, \tval-acc: 0.8252\n",
            "Epoch: 41 \t train-Loss: 0.0025, \tval-Loss: 0.0034, \tval-acc: 0.8547\n",
            "Epoch: 42 \t train-Loss: 0.0023, \tval-Loss: 0.0034, \tval-acc: 0.8565\n",
            "Epoch: 43 \t train-Loss: 0.0022, \tval-Loss: 0.0034, \tval-acc: 0.8581\n",
            "Epoch: 44 \t train-Loss: 0.0022, \tval-Loss: 0.0034, \tval-acc: 0.8571\n",
            "Epoch: 45 \t train-Loss: 0.0021, \tval-Loss: 0.0034, \tval-acc: 0.8571\n",
            "Epoch: 46 \t train-Loss: 0.0021, \tval-Loss: 0.0034, \tval-acc: 0.8553\n",
            "Epoch: 47 \t train-Loss: 0.0020, \tval-Loss: 0.0034, \tval-acc: 0.8547\n",
            "Epoch: 48 \t train-Loss: 0.0020, \tval-Loss: 0.0034, \tval-acc: 0.8576\n",
            "Epoch: 49 \t train-Loss: 0.0020, \tval-Loss: 0.0034, \tval-acc: 0.8587\n",
            "Epoch: 50 \t train-Loss: 0.0020, \tval-Loss: 0.0034, \tval-acc: 0.8573\n",
            "Epoch: 51 \t train-Loss: 0.0019, \tval-Loss: 0.0034, \tval-acc: 0.8601\n",
            "Epoch: 52 \t train-Loss: 0.0019, \tval-Loss: 0.0035, \tval-acc: 0.8576\n",
            "Epoch: 53 \t train-Loss: 0.0019, \tval-Loss: 0.0035, \tval-acc: 0.8584\n",
            "Epoch: 54 \t train-Loss: 0.0019, \tval-Loss: 0.0035, \tval-acc: 0.8578\n",
            "Epoch: 55 \t train-Loss: 0.0018, \tval-Loss: 0.0035, \tval-acc: 0.8592\n",
            "Epoch: 56 \t train-Loss: 0.0018, \tval-Loss: 0.0035, \tval-acc: 0.8577\n",
            "Epoch: 57 \t train-Loss: 0.0018, \tval-Loss: 0.0035, \tval-acc: 0.8581\n",
            "Epoch: 58 \t train-Loss: 0.0017, \tval-Loss: 0.0035, \tval-acc: 0.8560\n",
            "Epoch: 59 \t train-Loss: 0.0017, \tval-Loss: 0.0035, \tval-acc: 0.8593\n",
            "Epoch: 60 \t train-Loss: 0.0017, \tval-Loss: 0.0035, \tval-acc: 0.8606\n",
            "Epoch: 61 \t train-Loss: 0.0016, \tval-Loss: 0.0035, \tval-acc: 0.8621\n",
            "Epoch: 62 \t train-Loss: 0.0016, \tval-Loss: 0.0034, \tval-acc: 0.8637\n",
            "Epoch: 63 \t train-Loss: 0.0016, \tval-Loss: 0.0035, \tval-acc: 0.8622\n",
            "Epoch: 64 \t train-Loss: 0.0016, \tval-Loss: 0.0034, \tval-acc: 0.8618\n",
            "Epoch: 65 \t train-Loss: 0.0016, \tval-Loss: 0.0034, \tval-acc: 0.8631\n",
            "Epoch: 66 \t train-Loss: 0.0016, \tval-Loss: 0.0035, \tval-acc: 0.8631\n",
            "Epoch: 67 \t train-Loss: 0.0016, \tval-Loss: 0.0034, \tval-acc: 0.8631\n",
            "Epoch: 68 \t train-Loss: 0.0016, \tval-Loss: 0.0035, \tval-acc: 0.8616\n",
            "Epoch: 69 \t train-Loss: 0.0016, \tval-Loss: 0.0034, \tval-acc: 0.8609\n",
            "Epoch: 70 \t train-Loss: 0.0016, \tval-Loss: 0.0035, \tval-acc: 0.8628\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn0j6fqvVID_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
