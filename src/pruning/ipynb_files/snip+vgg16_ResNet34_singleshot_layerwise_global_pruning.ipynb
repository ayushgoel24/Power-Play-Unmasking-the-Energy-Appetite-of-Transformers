{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snip+vgg16/ResNet34/singleshot/layerwise/global_pruning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54cfceee71534afcabe7ea0e02f892c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cdcf9157f974f48b70c10db6bad8219",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d1ce47d34fc4def8ca7b68af88d48ae",
              "IPY_MODEL_97b5a47a8941400ab420b0e68fd79bf5"
            ]
          }
        },
        "3cdcf9157f974f48b70c10db6bad8219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d1ce47d34fc4def8ca7b68af88d48ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_48fccb3325a3460893f9ed261f3749b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f599048a6450430190efab5db09a1f86"
          }
        },
        "97b5a47a8941400ab420b0e68fd79bf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f7b560a5bd649fa936a00c4930340b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:03&lt;00:00, 46547770.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09eead5cd3394befb5e33e2236603476"
          }
        },
        "48fccb3325a3460893f9ed261f3749b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f599048a6450430190efab5db09a1f86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f7b560a5bd649fa936a00c4930340b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09eead5cd3394befb5e33e2236603476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJhuOudkJbah"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.datasets import CIFAR10, CIFAR100\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize\n",
        "from torchvision import transforms\n",
        "\n",
        "import copy\n",
        "import types\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upR2Jg4kJhAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4125a0-bdeb-45ed-f1e1-d4e2ee289a10"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8gTFaD2VMKY"
      },
      "source": [
        "def forward_new(self, x):\n",
        "  return F.conv2d(x, self.weight * self.w_mask, self.bias,\\\n",
        "                         self.stride, self.padding, self.dilation, self.groups) if isinstance(self, nn.Conv2d)\\\n",
        "                         else F.linear(x, self.weight * self.w_mask, self.bias)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywQg3YOcjrCO"
      },
      "source": [
        "def layer_mask_gen(model, keep_ratio):\n",
        "    layer_num=0\n",
        "    masks = []\n",
        "    for layer in model.modules():\n",
        "      \n",
        "      if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "        absolute_gradient =torch.abs(layer.w_mask.grad)  \n",
        "\n",
        "        value = absolute_gradient.reshape(-1, )\n",
        "        #value = torch.hstack(value)\n",
        "        sum_of_values = value.sum()\n",
        "        final_val = value/sum_of_values\n",
        "\n",
        "        req_params = (keep_ratio[layer_num] * len(final_val) )\n",
        "        req_params = int(req_params)\n",
        "        top_K = torch.topk(final_val, req_params, sorted=True)[0]\n",
        "\n",
        "        masks.append(absolute_gradient/sum_of_values >= top_K[len(top_K)-1])\n",
        "        layer_num +=1           \n",
        "\n",
        "    return masks\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elxkXCWGAnqf"
      },
      "source": [
        "def mask_gen(model, keep_ratio):\n",
        "    absolute_gradients= []\n",
        "    absolute_gradients =[torch.abs(layer.w_mask.grad) for layer in model.modules() if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)] \n",
        "\n",
        "    value = [each_lay_grad.reshape(-1, ) for each_lay_grad in absolute_gradients]\n",
        "    value = torch.hstack(value)\n",
        "    sum_of_values = value.sum()\n",
        "    final_val = value/sum_of_values\n",
        "\n",
        "    req_params = (len(final_val) * keep_ratio)\n",
        "    req_params = int(req_params)\n",
        "    top_K = torch.topk(final_val, req_params, sorted=True)[0]\n",
        "    \n",
        "    \n",
        "    masks = []\n",
        "    masks = [layer_gradient/sum_of_values >= top_K[len(top_K)-1] for layer_gradient in absolute_gradients]\n",
        "\n",
        "    return masks"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz8CuDu69QVw"
      },
      "source": [
        "def fb_training(model_fb, keep_ratio, train_dataloader, generate_mask, device):\n",
        "    \n",
        "    X, Y = next(iter(train_dataloader))\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    \n",
        "    model_fb = copy.deepcopy(model_fb)\n",
        "    \n",
        "\n",
        "    for layer in model_fb.modules():\n",
        "      #print(\"current_layer _before\", layer)\n",
        "      if isinstance(layer, nn.Conv2d) or isinstance(layer,nn.Linear):\n",
        "        layer.w_mask = nn.Parameter(torch.ones(layer.weight.shape).to(device)) \n",
        "        nn.init.xavier_normal_(layer.weight)\n",
        "        layer.weight.requires_grad = False\n",
        "        layer.forward = types.MethodType(forward_new, layer)\n",
        "     \n",
        "\n",
        "    model_fb.zero_grad()\n",
        "    out = model_fb.forward(X)\n",
        "    loss = F.nll_loss(out, Y)\n",
        "    loss.backward()\n",
        "\n",
        "    return generate_mask(model_fb, keep_ratio)\n",
        "\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYWcIZzgj_pZ"
      },
      "source": [
        "def freeze(gradients):\n",
        "  return gradients*mask\n",
        "\n",
        "def activate_hook(mask):\n",
        "  return freeze(grads)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwTA713GJg4o"
      },
      "source": [
        "def mask_app(model, keep_masks):\n",
        "\n",
        "    layer_prun=[]\n",
        "    i=0\n",
        "    for layer in model.modules():\n",
        "      if layer == nn.Conv2d or layer ==nn.Linear:\n",
        "        layer_prun.append(layer) \n",
        "        assert layer.weight.shape == keep_masks[i].shape\n",
        "        layer.weight.data[keep_masks[i].shape==0.] =0.\n",
        "        layer.weight.register_hook(activate_hook(keep_masks[i]))\n",
        "        i+=1\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZNohcSqJMci"
      },
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "\n",
        "       \n",
        "\n",
        "        self.convol = nn.Sequential(\n",
        "                  nn.Conv2d(3, 64, kernel_size= 3, padding=1), \n",
        "                  nn.BatchNorm2d(64),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(64, 64, kernel_size=3, padding=1), \n",
        "                  nn.BatchNorm2d(64),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  nn.Conv2d(64, 128, kernel_size = 3, padding=1), \n",
        "                  nn.BatchNorm2d(128),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(128, 128, kernel_size = 3, padding=1), \n",
        "                  nn.BatchNorm2d(128),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  nn.Conv2d(128, 256, kernel_size = 3, padding=1), \n",
        "                  nn.BatchNorm2d(256),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(256, 256, kernel_size=3, padding = 1), \n",
        "                  nn.BatchNorm2d(256),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(256, 256, kernel_size = 3, padding= 1), \n",
        "                  nn.BatchNorm2d(256),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  nn.Conv2d(256, 512, kernel_size = 3,padding=1), \n",
        "                  nn.BatchNorm2d(512),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(512, 512, kernel_size = 3, padding = 1), \n",
        "                  nn.BatchNorm2d(512),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(512, 512, kernel_size=3 , padding = 1), \n",
        "                  nn.BatchNorm2d(512),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  nn.Conv2d(512, 512, kernel_size = 3, padding = 1), \n",
        "                  nn.BatchNorm2d(512),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(512, 512, kernel_size = 3, padding = 1), \n",
        "                  nn.BatchNorm2d(512),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(512, 512, kernel_size = 3, padding = 1), \n",
        "                  nn.BatchNorm2d(512),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "                  \n",
        "              )\n",
        "        \n",
        "        self.Linear = nn.Sequential(\n",
        "                  nn.Linear(512, 512),  \n",
        "                  nn.ReLU(True),\n",
        "                  nn.BatchNorm1d(512),  \n",
        "                  nn.Linear(512, 512),\n",
        "                  nn.ReLU(True),\n",
        "                  nn.BatchNorm1d(512),  \n",
        "                  nn.Linear(512, num_classes),)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convol(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.Linear(x)  \n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvQ7tPs0EqqQ"
      },
      "source": [
        "class SimpleResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channel_size, out_channel_size, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel_size, out_channel_size, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel_size)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channel_size, out_channel_size, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel_size)\n",
        "\n",
        "        if stride == 1:\n",
        "            self.shortcut = nn.Identity()\n",
        "        else:\n",
        "            self.shortcut = nn.Conv2d(in_channel_size, out_channel_size, kernel_size=1, stride=stride, bias=False)\n",
        "        self.bn_shortcut= nn.BatchNorm2d(out_channel_size)\n",
        "        self.relu_shortcut = nn.ReLU(inplace=True)\n",
        " \n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        \n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        shortcut = self.shortcut(x)\n",
        "        shortcut= self.bn_shortcut(shortcut)\n",
        "        \n",
        "        out = self.relu_shortcut(out + shortcut)\n",
        "        \n",
        "        return out\n",
        "\n",
        "    def init_weights(self, m):\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_normal_(m.weight, 1.732)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHKaW7lUErZ4"
      },
      "source": [
        "class ResNet34(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
        "            \n",
        "            SimpleResidualBlock(64, 64, 1),\n",
        "            \n",
        "            SimpleResidualBlock(64, 64, 1),\n",
        "            \n",
        "            SimpleResidualBlock(64, 64, 1),\n",
        "            \n",
        "            SimpleResidualBlock(64, 128, 2),\n",
        "            \n",
        "            SimpleResidualBlock(128, 128, 1),\n",
        "\n",
        "            SimpleResidualBlock(128, 128, 1),\n",
        "            \n",
        "            SimpleResidualBlock(128, 128, 1),\n",
        "\n",
        "            SimpleResidualBlock(128, 256, 2),\n",
        "\n",
        "            SimpleResidualBlock(256, 256, 1),\n",
        "\n",
        "            SimpleResidualBlock(256, 256, 1),\n",
        "\n",
        "            SimpleResidualBlock(256, 256, 1),\n",
        "\n",
        "            SimpleResidualBlock(256, 256, 1),\n",
        "\n",
        "            SimpleResidualBlock(256, 256, 1),\n",
        "\n",
        "            SimpleResidualBlock(256, 512, 2),\n",
        "\n",
        "            SimpleResidualBlock(512, 512, 1),\n",
        "            \n",
        "            SimpleResidualBlock(512, 512, 1),\n",
        "            \n",
        "            nn.AdaptiveAvgPool2d((1, 1)), \n",
        "            \n",
        "            nn.Flatten(),\n",
        "        )\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.linear_output = nn.Linear(512,num_classes) \n",
        "\n",
        "        \n",
        "               \n",
        "    def forward(self, x):\n",
        "        embedding = self.layers(x) \n",
        "        output = self.linear_output(self.relu(embedding))\n",
        "     \n",
        "        return output      \n",
        "\n",
        "\n",
        "    def init_weights(self, m):\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m,nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight, 1.732)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqaAJmkYJz-R"
      },
      "source": [
        "def training(epoch, model, optimizer, scheduler, criterion, train_loader):\n",
        "  model.train()\n",
        "  avg_loss = 0.0\n",
        "  av_loss=0.0\n",
        "  total=0\n",
        "  for batch_num, (feats, labels) in enumerate(train_loader):\n",
        "      feats, labels = feats.to(device), labels.to(device)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(feats)\n",
        "\n",
        "\n",
        "      loss = criterion(outputs, labels.long())\n",
        "      loss.backward()\n",
        "      \n",
        "      optimizer.step()\n",
        "      \n",
        "      avg_loss += loss.item()\n",
        "      av_loss += loss.item() \n",
        "      total +=len(feats) \n",
        "\n",
        "      torch.cuda.empty_cache()\n",
        "      del feats\n",
        "      del labels\n",
        "      del loss\n",
        "\n",
        "  del train_loader\n",
        "\n",
        "  return avg_loss/total\n",
        "  "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrtnoMLCJz7H"
      },
      "source": [
        "def validate(epoch, model, criterion, data_loader):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        running_loss, accuracy,total  = 0.0, 0.0, 0\n",
        "\n",
        "        \n",
        "        for i, (X, Y) in enumerate(data_loader):\n",
        "            \n",
        "            X, Y = X.to(device), Y.to(device)\n",
        "            output= model(X)\n",
        "            loss = criterion(output, Y.long())\n",
        "\n",
        "            _,pred_labels = torch.max(F.softmax(output, dim=1), 1)\n",
        "            pred_labels = pred_labels.view(-1)\n",
        "            \n",
        "            accuracy += torch.sum(torch.eq(pred_labels, Y)).item()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total += len(X)\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "            del X\n",
        "            del Y\n",
        "        \n",
        "        return running_loss/total, accuracy/total"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhGmS_ifLyMb"
      },
      "source": [
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Jf35E4Jz1N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "54cfceee71534afcabe7ea0e02f892c4",
            "3cdcf9157f974f48b70c10db6bad8219",
            "4d1ce47d34fc4def8ca7b68af88d48ae",
            "97b5a47a8941400ab420b0e68fd79bf5",
            "48fccb3325a3460893f9ed261f3749b5",
            "f599048a6450430190efab5db09a1f86",
            "6f7b560a5bd649fa936a00c4930340b9",
            "09eead5cd3394befb5e33e2236603476"
          ]
        },
        "outputId": "25d4178d-44af-43b9-afaa-41aef0618851"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "      model_dict = {\"VGG16\": VGG16, \"ResNet34\": ResNet34}\n",
        "      dataset_dict = {\"CIFAR10\":CIFAR10, \"CIFAR100\":CIFAR100}\n",
        "      ####arguments#############\n",
        "      model = ResNet34\n",
        "      dataset=CIFAR100\n",
        "      lr_rate = 0.1\n",
        "      step_size = 20\n",
        "      batch_size = 128\n",
        "      weight_decay = 0.0005\n",
        "      epochs = 70\n",
        "      layer_wise = False\n",
        "      ####arguments############\n",
        "\n",
        "      if layer_wise == False:\n",
        "        keep_ratio = 0.05\n",
        "      else:\n",
        "        if model == VGG16:\n",
        "          layer_mult = 16\n",
        "        elif model_dict[\"ResNet34\"] == model:\n",
        "          layer_mult = 37\n",
        "        elif model == ResNet50:\n",
        "          layer_mult = 53\n",
        "        keep_ratio = [0.05]* layer_mult\n",
        "      \n",
        "    \n",
        "      if dataset == dataset_dict[\"CIFAR10\"]:\n",
        "        num_classes =10\n",
        "      elif dataset== dataset_dict[\"CIFAR100\"] :\n",
        "        num_classes = 100\n",
        "\n",
        "      generate_mask= mask_gen if layer_wise == False else layer_mask_gen # gloabl pruning or layer_wise pruning\n",
        "      print(num_classes)\n",
        "      \n",
        "\n",
        "      net = model(num_classes=num_classes) #num_classes for CIFAR10 = 10 for CIFAR100= 100\n",
        "      #print(net)\n",
        "      optimiser = optim.SGD( net.parameters(), lr=0.1, momentum=0.9, weight_decay=weight_decay)\n",
        "      scheduler = optim.lr_scheduler.StepLR(optimiser, step_size=20, gamma=0.1)\n",
        "\n",
        "      transform_train = transforms.Compose([\n",
        "      transforms.RandomCrop(32, padding=4),\n",
        "      transforms.RandomHorizontalFlip(),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                        (0.2023, 0.1994, 0.2010)),\n",
        "      ])\n",
        "\n",
        "      transform_test = transforms.Compose([\n",
        "      transforms.RandomCrop(32, padding=4),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
        "                        (0.2023, 0.1994, 0.2010)),\n",
        "      ])\n",
        "\n",
        "      train_dataset = dataset('_dataset', True, transform_train, download=True)\n",
        "      test_dataset = dataset('_dataset', False, transform_test, download=False)\n",
        "\n",
        "      train_loader = DataLoader( train_dataset, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "      val_loader = DataLoader( test_dataset, batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "      net = net.to(device)\n",
        "      \n",
        "      #masks = fb_training(net, keep_ratio, train_loader, generate_mask,device) \n",
        "      #mask_app(net, masks)\n",
        "      \n",
        "      \n",
        "      \n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "      for epoch in range(epochs):\n",
        "\n",
        "          train_loss = training(epoch, net, optimiser, scheduler, criterion,train_loader)\n",
        "\n",
        "          start_time = time.time()\n",
        "          val_loss, val_acc = validate(epoch, net, criterion, val_loader)\n",
        "          end_time = time.time()\n",
        "          \n",
        "\n",
        "          scheduler.step()\n",
        "\n",
        "\n",
        "          print('Epoch: {} \\t train-Loss: {:.4f}, \\tval-Loss: {:.4f}, \\tval-acc: {:.4f} \\tinference_time: {:.4f}:'.format(epoch+1,  train_loss, val_loss, val_acc, end_time - start_time))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to _dataset/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54cfceee71534afcabe7ea0e02f892c4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting _dataset/cifar-100-python.tar.gz to _dataset\n",
            "Epoch: 1 \t train-Loss: 0.0330, \tval-Loss: 0.0295, \tval-acc: 0.1238 \tinference_time: 1.8495:\n",
            "Epoch: 2 \t train-Loss: 0.0276, \tval-Loss: 0.0268, \tval-acc: 0.1818 \tinference_time: 1.6747:\n",
            "Epoch: 3 \t train-Loss: 0.0255, \tval-Loss: 0.0255, \tval-acc: 0.2066 \tinference_time: 1.7483:\n",
            "Epoch: 4 \t train-Loss: 0.0240, \tval-Loss: 0.0252, \tval-acc: 0.2391 \tinference_time: 1.8480:\n",
            "Epoch: 5 \t train-Loss: 0.0230, \tval-Loss: 0.0237, \tval-acc: 0.2602 \tinference_time: 1.8013:\n",
            "Epoch: 6 \t train-Loss: 0.0220, \tval-Loss: 0.0236, \tval-acc: 0.2572 \tinference_time: 1.7557:\n",
            "Epoch: 7 \t train-Loss: 0.0214, \tval-Loss: 0.0220, \tval-acc: 0.2900 \tinference_time: 1.9088:\n",
            "Epoch: 8 \t train-Loss: 0.0208, \tval-Loss: 0.0219, \tval-acc: 0.2961 \tinference_time: 1.8389:\n",
            "Epoch: 9 \t train-Loss: 0.0214, \tval-Loss: 0.0310, \tval-acc: 0.2800 \tinference_time: 1.7865:\n",
            "Epoch: 10 \t train-Loss: 0.0203, \tval-Loss: 0.0209, \tval-acc: 0.3203 \tinference_time: 1.8490:\n",
            "Epoch: 11 \t train-Loss: 0.0197, \tval-Loss: 0.0213, \tval-acc: 0.3089 \tinference_time: 1.8843:\n",
            "Epoch: 12 \t train-Loss: 0.0192, \tval-Loss: 0.0210, \tval-acc: 0.3261 \tinference_time: 1.7589:\n",
            "Epoch: 13 \t train-Loss: 0.0190, \tval-Loss: 0.0204, \tval-acc: 0.3382 \tinference_time: 1.8216:\n",
            "Epoch: 14 \t train-Loss: 0.0191, \tval-Loss: 0.0199, \tval-acc: 0.3458 \tinference_time: 1.7613:\n",
            "Epoch: 15 \t train-Loss: 0.0189, \tval-Loss: 0.0193, \tval-acc: 0.3647 \tinference_time: 1.7897:\n",
            "Epoch: 16 \t train-Loss: 0.0184, \tval-Loss: 0.0194, \tval-acc: 0.3580 \tinference_time: 1.7373:\n",
            "Epoch: 17 \t train-Loss: 0.0181, \tval-Loss: 0.1065, \tval-acc: 0.3436 \tinference_time: 1.7502:\n",
            "Epoch: 18 \t train-Loss: 0.0179, \tval-Loss: 0.0513, \tval-acc: 0.3490 \tinference_time: 1.7859:\n",
            "Epoch: 19 \t train-Loss: 0.0177, \tval-Loss: 0.0244, \tval-acc: 0.2912 \tinference_time: 1.8063:\n",
            "Epoch: 20 \t train-Loss: 0.0174, \tval-Loss: 0.0197, \tval-acc: 0.3589 \tinference_time: 1.6550:\n",
            "Epoch: 21 \t train-Loss: 0.0142, \tval-Loss: 0.0147, \tval-acc: 0.4927 \tinference_time: 1.7712:\n",
            "Epoch: 22 \t train-Loss: 0.0130, \tval-Loss: 0.0145, \tval-acc: 0.4980 \tinference_time: 1.8699:\n",
            "Epoch: 23 \t train-Loss: 0.0124, \tval-Loss: 0.0143, \tval-acc: 0.5089 \tinference_time: 1.7655:\n",
            "Epoch: 24 \t train-Loss: 0.0120, \tval-Loss: 0.0142, \tval-acc: 0.5148 \tinference_time: 1.7621:\n",
            "Epoch: 25 \t train-Loss: 0.0117, \tval-Loss: 0.0143, \tval-acc: 0.5133 \tinference_time: 1.7397:\n",
            "Epoch: 26 \t train-Loss: 0.0114, \tval-Loss: 0.0143, \tval-acc: 0.5151 \tinference_time: 1.7845:\n",
            "Epoch: 27 \t train-Loss: 0.0111, \tval-Loss: 0.0141, \tval-acc: 0.5216 \tinference_time: 1.8337:\n",
            "Epoch: 28 \t train-Loss: 0.0109, \tval-Loss: 0.0137, \tval-acc: 0.5294 \tinference_time: 1.7973:\n",
            "Epoch: 29 \t train-Loss: 0.0107, \tval-Loss: 0.0139, \tval-acc: 0.5259 \tinference_time: 1.7769:\n",
            "Epoch: 30 \t train-Loss: 0.0105, \tval-Loss: 0.0139, \tval-acc: 0.5270 \tinference_time: 1.8041:\n",
            "Epoch: 31 \t train-Loss: 0.0103, \tval-Loss: 0.0138, \tval-acc: 0.5229 \tinference_time: 1.7773:\n",
            "Epoch: 32 \t train-Loss: 0.0100, \tval-Loss: 0.0141, \tval-acc: 0.5276 \tinference_time: 1.7471:\n",
            "Epoch: 33 \t train-Loss: 0.0098, \tval-Loss: 0.0139, \tval-acc: 0.5348 \tinference_time: 1.8988:\n",
            "Epoch: 34 \t train-Loss: 0.0097, \tval-Loss: 0.0139, \tval-acc: 0.5259 \tinference_time: 1.8399:\n",
            "Epoch: 35 \t train-Loss: 0.0095, \tval-Loss: 0.0143, \tval-acc: 0.5130 \tinference_time: 1.8855:\n",
            "Epoch: 36 \t train-Loss: 0.0094, \tval-Loss: 0.0142, \tval-acc: 0.5263 \tinference_time: 1.8806:\n",
            "Epoch: 37 \t train-Loss: 0.0092, \tval-Loss: 0.0141, \tval-acc: 0.5254 \tinference_time: 1.9523:\n",
            "Epoch: 38 \t train-Loss: 0.0091, \tval-Loss: 0.0140, \tval-acc: 0.5292 \tinference_time: 1.9430:\n",
            "Epoch: 39 \t train-Loss: 0.0088, \tval-Loss: 0.0143, \tval-acc: 0.5228 \tinference_time: 1.8858:\n",
            "Epoch: 40 \t train-Loss: 0.0087, \tval-Loss: 0.0143, \tval-acc: 0.5246 \tinference_time: 1.9859:\n",
            "Epoch: 41 \t train-Loss: 0.0072, \tval-Loss: 0.0132, \tval-acc: 0.5573 \tinference_time: 1.8721:\n",
            "Epoch: 42 \t train-Loss: 0.0066, \tval-Loss: 0.0131, \tval-acc: 0.5590 \tinference_time: 1.9282:\n",
            "Epoch: 43 \t train-Loss: 0.0063, \tval-Loss: 0.0130, \tval-acc: 0.5667 \tinference_time: 1.8865:\n",
            "Epoch: 44 \t train-Loss: 0.0061, \tval-Loss: 0.0130, \tval-acc: 0.5625 \tinference_time: 1.8082:\n",
            "Epoch: 45 \t train-Loss: 0.0059, \tval-Loss: 0.0131, \tval-acc: 0.5627 \tinference_time: 1.9791:\n",
            "Epoch: 46 \t train-Loss: 0.0057, \tval-Loss: 0.0132, \tval-acc: 0.5675 \tinference_time: 2.0049:\n",
            "Epoch: 47 \t train-Loss: 0.0055, \tval-Loss: 0.0132, \tval-acc: 0.5632 \tinference_time: 1.9346:\n",
            "Epoch: 48 \t train-Loss: 0.0054, \tval-Loss: 0.0133, \tval-acc: 0.5604 \tinference_time: 1.8109:\n",
            "Epoch: 49 \t train-Loss: 0.0053, \tval-Loss: 0.0131, \tval-acc: 0.5654 \tinference_time: 1.9395:\n",
            "Epoch: 50 \t train-Loss: 0.0052, \tval-Loss: 0.0133, \tval-acc: 0.5637 \tinference_time: 1.9738:\n",
            "Epoch: 51 \t train-Loss: 0.0051, \tval-Loss: 0.0134, \tval-acc: 0.5627 \tinference_time: 1.7817:\n",
            "Epoch: 52 \t train-Loss: 0.0050, \tval-Loss: 0.0133, \tval-acc: 0.5655 \tinference_time: 1.7951:\n",
            "Epoch: 53 \t train-Loss: 0.0048, \tval-Loss: 0.0135, \tval-acc: 0.5664 \tinference_time: 1.7670:\n",
            "Epoch: 54 \t train-Loss: 0.0047, \tval-Loss: 0.0134, \tval-acc: 0.5672 \tinference_time: 1.7180:\n",
            "Epoch: 55 \t train-Loss: 0.0046, \tval-Loss: 0.0136, \tval-acc: 0.5646 \tinference_time: 1.8412:\n",
            "Epoch: 56 \t train-Loss: 0.0045, \tval-Loss: 0.0137, \tval-acc: 0.5656 \tinference_time: 1.9250:\n",
            "Epoch: 57 \t train-Loss: 0.0044, \tval-Loss: 0.0138, \tval-acc: 0.5611 \tinference_time: 1.7989:\n",
            "Epoch: 58 \t train-Loss: 0.0043, \tval-Loss: 0.0138, \tval-acc: 0.5645 \tinference_time: 1.7210:\n",
            "Epoch: 59 \t train-Loss: 0.0042, \tval-Loss: 0.0139, \tval-acc: 0.5605 \tinference_time: 1.9755:\n",
            "Epoch: 60 \t train-Loss: 0.0041, \tval-Loss: 0.0139, \tval-acc: 0.5625 \tinference_time: 1.9130:\n",
            "Epoch: 61 \t train-Loss: 0.0038, \tval-Loss: 0.0138, \tval-acc: 0.5646 \tinference_time: 1.8158:\n",
            "Epoch: 62 \t train-Loss: 0.0037, \tval-Loss: 0.0140, \tval-acc: 0.5650 \tinference_time: 1.7201:\n",
            "Epoch: 63 \t train-Loss: 0.0037, \tval-Loss: 0.0138, \tval-acc: 0.5682 \tinference_time: 1.9120:\n",
            "Epoch: 64 \t train-Loss: 0.0037, \tval-Loss: 0.0138, \tval-acc: 0.5633 \tinference_time: 1.8824:\n",
            "Epoch: 65 \t train-Loss: 0.0036, \tval-Loss: 0.0140, \tval-acc: 0.5614 \tinference_time: 1.8234:\n",
            "Epoch: 66 \t train-Loss: 0.0037, \tval-Loss: 0.0137, \tval-acc: 0.5663 \tinference_time: 1.9285:\n",
            "Epoch: 67 \t train-Loss: 0.0036, \tval-Loss: 0.0139, \tval-acc: 0.5646 \tinference_time: 1.9245:\n",
            "Epoch: 68 \t train-Loss: 0.0036, \tval-Loss: 0.0139, \tval-acc: 0.5642 \tinference_time: 1.8267:\n",
            "Epoch: 69 \t train-Loss: 0.0036, \tval-Loss: 0.0138, \tval-acc: 0.5707 \tinference_time: 1.7745:\n",
            "Epoch: 70 \t train-Loss: 0.0035, \tval-Loss: 0.0138, \tval-acc: 0.5676 \tinference_time: 1.8367:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sqNE55SMZUT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}